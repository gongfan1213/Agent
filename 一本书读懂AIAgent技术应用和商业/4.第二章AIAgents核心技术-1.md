### |第2章|CHAPTER
### AI Agent核心技术
本章将帮助你理解有关AI Agent的核心技术，包括其工作原理、主要组成部分，以及如何利用LLM来增强其功能。我们还将介绍一些流行的AI Agent项目和构建框架，这些项目和框架已经在实践中证明了其价值，并且能够为AI Agent的未来发展提供有力的支持。
#### 2.1 AI Agent的技术基础
##### 2.1.1 当前的主流AI技术
AI技术发展到现在，主流的主要包括以下几种。

1. **机器学习**

机器学习（Machine Learning）是人工智能的一个分支，通过数据和算法训练模型，使计算机能够自动学习和改进。常见的机器学习算法有决策树、支持向量机、神经网络等。机器学习专注于使用数据和算法模仿人类学习的方式，逐步提高自身的准确性。

机器学习方法主要分为监督学习、无监督学习、半监督学习和强化学习。机器学习算法通常是使用旨在加速解决方案开发的框架创建的，例如TensorFlow和PyTorch。谷歌的AlphaGo就是一种基于机器学习的围棋AI，它通过学习人类棋手的棋谱和自我对弈来提高棋艺。

机器学习的应用场景非常广泛，如手势识别、市民出行选乘公交预测、待测微生物种类判别、基于运营商数据的个人征信评估、商品图片分类、广告点击行为预测、基于文本内容的垃圾短信识别等。

2. **深度学习**

深度学习（Deep Learning）是机器学习的一个子领域，它使用类似于人脑中的神经网络结构的算法来模拟和理解数据的特征。深度学习的核心是深度神经网络（Deep Neural Network，DNN），这些网络由多层（称为深度）的节点组成，能够学习数据的复杂模式。

深度学习引入了深度神经网络，具有多个隐藏层，能够学习更抽象、更高级别的特征，处理更复杂的问题。深度学习不需要手动进行特征工程，减少了人工干预的需求，降低了模型开发的门槛。目前，深度学习已在图像识别、语音识别、自然语言处理等领域取得了重大突破，其应用场景包括图像分类、风格迁移、姿势识别、实例分割等。

3. **自然语言处理**

自然语言处理（Natural Language Processing，NLP）是一门研究计算机与人类自然语言之间交互的学科。它涉及语音识别、文本理解、机器翻译、情感分析等技术，使计算机能够理解和处理人类语言。自然语言处理需要根据前后的内容进行界定，从中消除歧义性和模糊性，表达出真正的意义。自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。微软的小冰就是一种基于自然语言处理的聊天机器人，它可以与用户进行自然的语言交互。

自然语言处理的应用领域非常广泛，常见的应用系统有语音输入系统、语音控制系统、智能对话查询系统等。

4. **计算机视觉**

计算机视觉（Computer Vision，CV）是人工智能领域的一个重要分支，是一种让计算机能够从图像或多维数据中解释和理解视觉信息的技术。它可以模拟人类的视觉系统，实现对图像和视频中内容的识别、分类、定位、检测和理解等功能。计算机视觉的应用非常广泛，涵盖医疗影像分析、安全监控、无人驾驶机器人导航、内容创作、电子商务等众多领域，具体应用场景包括手势识别、手写数字识别、商品图片分类等。例如，谷歌的图像搜索技术就是计算机视觉的应用。

5. **语音识别**

语音识别（Automatic Speech Recognition，ASR）也称为自动语音识别，是将语音信号转换成文本的技术。它通过分析声音特征和语音模型实现对语音的识别和理解。语音识别通过对输入的语音信号进行预处理，提取出反映语音特征的关键参数，如梅尔频率倒谱系数（MFCC）、线性预测编码（LPC）等。这些特征参数能够反映语音的音调、音色和音速等属性，有助于后续的声学模型训练。语音识别技术已广泛应用于语音助手、语音控制、语音翻译等领域。比如苹果的Siri就是一种基于语音识别的智能助手。语音识别的应用领域非常广泛，常见的应用系统有语音输入系统、语音控制系统等。

6. **LLM**

LLM是一种能够生成与人类语言非常相似的文本并以自然方式理解提示的机器学习模型。通过分析数据中的统计模式，LLM可以预测给定输入后最可能出现的单词或短语。它们在大量的文本数据上进行训练，可以执行广泛的任务，包括文本总结、翻译、情感分析等。

7. **RAG**

目前，业界认为基于LLM的应用集中于两个方向：RAG（Retrieval-Augmented Generation，检索增强生成）和Agent。而作为LLM应用的两大方向之一，RAG技术让AI Agent在应用上实现了巨大的飞跃。这里，我们重点介绍一下RAG技术。

- **RAG的概念与特点**

RAG是一个为LLM提供外部知识源的概念，这使它能够生成准确且符合上下文的答案，同时能够减少模型幻觉。

最先进的LLM会接受大量的训练数据，将广泛的常识知识存储在神经网络的权重中。但在提示LLM生成训练数据之外的知识，例如最新知识、特定领域知识时，LLM的输出可能会导致事实不准确，这就是我们常说的模型幻觉。弥合LLM的常识与其他背景知识之间的差距非常重要，这可以帮助LLM生成更准确和更贴合背景的结果，同时减少幻觉。


传统的解决方法是通过微调神经网络模型来适应特定领域的专有信息。尽管这种技术很有效，但它属于计算密集型的，并且需要专业技术知识，因而难以灵活地适应不断变化的信息。2020年，Lewis等人的论文在知识密集型NLP任务中提出了一种更灵活的技术，称为检索增强生成（RAG）。在该论文中，研究人员将生成模型与检索器模块相结合，以提供来自外部知识源的附加信息，并且这些信息可以很方便地进行更新维护。

RAG将事实知识与LLM的推理能力分离，并存储在外部知识源中，使LLM可以轻松访问和更新。事实知识为非参数化知识（non-parametric knowledge），将会存储在外部知识源中，例如向量数据库。而LLM在训练期间学习到的参数化知识（parametric knowledge）会隐式地存储在神经网络的权重中。

![image](https://github.com/user-attachments/assets/ded34661-9c3d-46df-96fe-e330f7d4994c)


- **RAG的工作流程** 

RAG的工作流程主要包括检索、增强和生成三个步骤，如图2-1所示。
    - **检索（Retrieve）**：根据用户请求从外部知识源检索相关上下文。为此，使用嵌入模型将用户查询嵌入与向量数据库中的附加上下文相同的向量空间中。这允许执行相似性搜索，并返回向量数据库中最接近的前k个数据对象。
    - **增强（Augment）**：用户查询和检索到的附加上下文被填充到提示模板中。
    - **生成（Generate）**：检索增强提示被馈送到LLM。
- **RAG与AI Agent的关系**

如果说RAG是通过外挂知识达到让LLM在垂直领域应用落地的目的的，那么AI Agent就是让LLM学会现实世界中的各种规则，并利用这些规则执行目标任务。在LLM本就强大的功能基础上，RAG将其扩展为能访问特定领域或组织的内部知识库，所有这些都无须重新训练模型。这是一种经济高效地改进LLM输出的方法，让它在各种情境下都能保持相关性、准确性和实用性。具体体现为以下几点：
    - RAG可以作为AI Agent架构（比如LangChain）的一部分，用以为AI Agent提供更加丰富和准确的语言生成能力。
    - AI Agent可能使用LangChain来处理自然语言的任务，比如理解用户输入和生成响应。
    - AI Agent可以利用RAG技术来提高自身在特定任务（如问答或对话系统）中的性能，尤其是在需要外部知识来支持决策时。
在应用案例方面，可以使用LangChain，结合OpenAI LLM、Weaviate向量数据库在Python中实现RAG Pipeline（检索增强生成流程）。
- **Agent检索增强生成**

将RAG置于AI Agent架构中可以大幅提升AI Agent的能力，但RAG在LLM中也会存在一些局限性。
    - 在RAG模式中，检索、增强和生成由不同的进程管理。每个进程可能由具有不同提示的LLM协助。然而，直接与用户交互的生成LLM通常最清楚如何响应用户的查询。检索LLM可能不会像生成LLM那样解释用户的意图，可能会提供不必要的信息，这可能会降低其响应能力。
    - 每个问题都会执行一次检索，没有来自LLM的任何反馈循环。如果搜索查询或搜索词等因素导致检索结果不相关，而LLM缺乏纠正这种情况的机制，它可能会编造一个答案。 
    - 检索的上下文一旦提供就不可更改，且无法扩展。例如，某个研究结果需要进一步检索其他信息，若检索到的文档引用了应进一步检索的另一文档，则会因为缺少必要文档而无法继续检索。
    - RAG模式不支持多步骤迭代搜索。

为了解决这些问题，有人提出了Agent检索增强生成模式：一个由LLM提供支持的智能Agent，用于管理与用户的对话。Agent自主决定何时使用外部工具进行研究，指定一个或多个搜索查询，进行研究，审查结果，并决定是否继续进一步研究或寻求用户的澄清。此过程一直持续到Agent认为自己准备好向用户提供答案为止。

在实现方法上，可以借助Azure OpenAI的功能调用能力来实现一个能自主使用搜索工具查找所需信息以协助处理用户请求的Agent。仅这一项功能就简化了RAG模式的传统实现方式（如前所述，包括查询改写、增强和生成的独立步骤）。Agent使用系统定义的角色和目标与用户交互，同时了解其可以使用的搜索工具。当Agent需要查找它不具备的知识时，它会指定搜索查询并向搜索引擎发出信号以检索所需的答案。这个过程更像是人类行为，会比纯RAG模式更有效。在RAG模式中，知识检索是一个单独的过程，无论是否需要都向聊天机器人提供信息。
##### 2.1.2 主流AI技术与AI Agent的关系
一直以来，AI Agent都被研究者们基于各种更先进的AI技术构建。机器学习、深度学习、自然语言处理、计算机视觉、语音识别等技术，与AI Agent有着密切的关系和内在联系，它们都是AI Agent的基础技术，为AI Agent提供了丰富的功能和能力，并构成了AI技术丰富多彩的应用场景。

比如机器学习和深度学习可以帮助AI Agent学习与理解客户的需求和问题，自然语言处理和语音识别可以帮助AI Agent与客户进行自然语言交互，计算机视觉可以帮助AI Agent识别与理解图像和视频，从而实现更加智能化的服务。AI Agent与这些技术的关联主要体现以下几个方面：
- **数据驱动**：AI Agent的核心是LLM，它需要大量的数据和算法来训练与优化。机器学习、深度学习、自然语言处理、计算机视觉、语音识别等技术都是数据驱动的，它们需要大量的数据和算法来训练与优化模型。
- **智能化服务**：AI Agent的目标是为客户提供智能化的服务，机器学习、深度学习、自然语言处理、计算机视觉、语音识别等技术都可以帮助AI Agent实现这一目标。
- **人机交互**：AI Agent需要与客户进行有效的人机交互，以便更好地理解客户的需求和问题。自然语言处理和语音识别等技术，可以帮助AI Agent理解与处理客户的语言，计算机视觉可以帮助AI Agent理解与处理客户的图像和视频。
- **智能决策**：AI Agent需要具备智能决策和执行能力，以便更好地为客户提供服务。机器学习和深度学习等技术可以帮助AI Agent学习与理解客户的需求和问题，从而做出更加智能化的决策。
- **应用场景**：AI Agent的应用场景非常广泛，机器学习、深度学习、自然语言处理、计算机视觉、语音识别等技术也都有着广泛的应用场景。

LLM的出现离不开深度学习、机器学习等技术。LLM是基于深度学习的模型，可以自动学习自然语言的特征，进而对文本进行处理和生成。模型的基础是神经网络，通过在大量语料库上的预训练，模型能够自动提取语言的特征，并对新的文本进行处理。常见的LLM有BERT、GPT等。LLM和人工智能密切相关，它是人工智能在自然语言处理领域的一种具体应用。人工智能的发展离不开对语言的理解和表达能力，而LLM为此提供了强有力的技术支持。它能够帮助计算机理解人类语言，分析语义和语法结构，从而更好地理解人们的需求和意图。

当下，AI Agent主要基于LLM构建，但也会因应用场景等的不同而选择领域小模型或者更垂直的功能性模型，将多种技术融合应用以提升能力。

关于LLM如何赋能AI Agent，下一节将为大家揭晓。

#### 2.2 基于LLM的AI Agent形态与特点

所谓基于LLM的AI Agent（LLM-based Agent），就是基于LLM的人工智能体，它可以感知环境、进行决策和执行动作，从而为客户提供自然语言处理、语音识别、自动化回复等服务，帮助企业提高客户满意度和运营效率。LLM作为“大脑”，为当代AI Agent提供了强大的逻辑思考等能力。

##### 2.2.1 从LLM说起
LLM是一种基于神经网络的自然语言处理技术，可以学习和预测自然语言文本的规律和模式。它是基于海量文本数据训练的深度学习模型，不仅能够生成自然语言文本，更能够深入理解文本含义，处理各种自然语言任务，如文本摘要、问答、翻译等。简单理解，LLM就是一个能够理解和生成自然语言的AI程序。

在LLM中，神经网络模型可以通过学习大量的语料数据，自动提取自然语言文本中的特征和模式，从而实现自然语言的理解和生成。

LLM的基本思想是将自然语言文本看作一种序列数据，例如单词序列或字符序列。神经网络模型可以通过输入这些序列数据并进行多层神经元的计算和转换，来生成对应的输出序列。在LLM中，神经网络模型通常采用循环神经网络（RNN）、长短期记忆网络（LSTM）、门控循环单元（GRU）等结构来处理序列数据的信息。 

LLM的发展源远流长，早在20世纪80年代，科学家们就开始尝试用神经网络处理自然语言，但当时受限于计算机硬件和数据资源，仅能处理简单任务。随着技术的进步，深度神经网络开始应用于自然语言处理。图2-2展示了2019年以来的LLM发展情况。

![image](https://github.com/user-attachments/assets/5963b714-9eba-4f49-8cc8-6402f5d397b3)


（图2-2 2019年以来的LLM发展情况 图片来源：论文“A Survey of Large Language Model”）

LLM的简单发展历程为：2013年，Tomas Mikolov等人推出RNNLM，能预测和生成文本；2014年，Bengio等人提出LSTMLM，解决了RNNLM存在的问题；2017年，谷歌的Transformer架构为后来的LLM奠定基础；2018年，OpenAI推出GPT模型，参数达1.17亿个，表现优异；2019年，更强的第二代GPT模型问世，参数增至15亿个，文本生成能力更强；2022年，ChatGPT引发全球关注；至2023年10月，公开显示国内已有超过200个LLM。

LLM的主要算法包括神经网络架构、词向量表示、模型训练及模型评估等。与传统的自然语言处理技术相比，LLM具有以下几个特点：

- **数据驱动**：LLM需要大量的语料数据来进行训练和优化，从而学习自然语言的规律和模式。

- **端到端学习**：LLM可以直接从原始文本数据中学习，不需要进行人工特征工程或规则设计。

- **上下文感知**：LLM可以根据上下文信息来生成自然语言文本，从而实现更加准确和连贯的响应。

- **通用性**：LLM可以应用于多种自然语言处理任务，例如文本分类、机器翻译、聊天机器人等。

这些特点使得LLM具备内容生成、语义理解、逻辑推理、多语言处理、情感分析、自我学习等多种能力，为AI Agent的构建提供了更好的基础。

##### 2.2.2 基于LLM的AI Agent的特点

宏观上讲，AI Agent可以是一种智能生命，能够脱离人的控制，自主决策和执行任务。在LLM背景下，AI Agent可以理解为某种在LLM基础上，能自主感知理解、规划决策、执行复杂任务的Agent，它可以通过独立思考和调用工具逐步完成给定的目标，无须人类指定每一步的操作。AI Agent并非ChatGPT等LLM的升级版，它不仅告诉你“如何做”，更会帮你去做。从这个角度而言，如果Copilot是副驾驶，那么AI Agent就是主驾驶。

1. **最简单的AI Agent表达式**

在具体行动中，一个精简的AI Agent决策流程包括三步，即感知（Perception）→规划（Planning）→行动（Action），也就是业界常说的PPA，如图2-3所示。
    - **感知**：AI Agent从环境中收集信息并从中提取相关知识的能力。
    - **规划**：AI Agent为了某一目标而做出决策的过程。
    - **行动**：AI基于环境和规划做出的动作。
（图2-3 PPA示意图 ）

![image](https://github.com/user-attachments/assets/d3cd535e-a883-4ec6-a81e-1920e1eeccb2)


这种表达使得AI Agent的决策流程类似于人类“做事情”的过程。AI Agent通过感知从环境中收集信息并提取相关知识，然后通过规划为了达到某个目标做出决策。最后通过行动基于环境和规划做出具体的动作。而行动又通过观察（Observation）成为进一步感知的前提和基础，形成自主地闭环学习过程。

这一过程就像人类从实践到认知，从实践开始，经过实践得到理论认识，再回到实践中去。因此AI Agent也像人类的认知与成长一样，需要“知行合一”地进化。

这几点也是断定某个软件或者硬件是不是AI Agent的主要标准。

一般而言，基于AI Agent的自主性、感知能力、学习能力、适应性、交互性和目标导向性等特性，如果一个系统或者产品拥有自我决策和学习能力，并且能够在



其环境中独立操作，那么它就可以被视为AI Agent。在这个更为广义的特征之下，AI Agent存在的环境将更加宽泛，种类也更加繁多。

当然，研究基于LLM的AI Agent，首先要看它是不是基于LLM构建的，或者是否引入了生成式AI技术。如果该产品能够自动且智能地使用自然语言来理解指令、提供信息、与用户互动并执行复杂的任务，同时不断学习并优化其性能，那么它很可能是一种基于LLM的AI Agent。

一个更完整的AI Agent一定是与环境充分交互的，它包括两部分：一是Agent的部分，二是环境的部分。Agent就如同物理世界中的人类，物理世界就是人类的外部环境。对于外部环境的交互，目前国内外关于AI Agent新的共识正在逐渐形成：

第一，AI Agent需要调用外部工具。

第二，调用工具的方式就是输出代码——由LLM大脑输出一种可执行的代码，像是一个语义分析器，由它理解每句话的含义，然后将其转换成机器指令，最后再调用外部的工具来执行或生成答案。 


在这种认知下，当前主流的AI Agent架构是由OpenAI推出的“Agent = LLM + 记忆 + 规划 + 工具使用”四件套，每一部分都是AI Agent必不可少的组件。当然，AI Agent架构并不是唯一的，只要能够体现自主感知、规划决策、执行复杂任务等特性，能够让Agent成为合格的自主Agent的架构，就是成功的架构。

不同的研究机构与企业会给予AI Agent不同的定义以及架构，比如复旦大学NLP团队在论文“The Rise and Potential of Large Language Model Based Agents: A Survey”中提出的基于LLM的Agent的概念框架，由大脑、感知、行动三个部分组成。在这个架构中，作为控制器的大脑模块承担记忆、思考和决策等基本任务；感知模块负责感知和处理来自外部环境的多模态信息；行动模块负责使用工具执行任务并影响周围环境。中国人民大学高瓴人工智能学院在论文“A Survey on Large Language Model based Autonomous Agents”中提出的Agent框架，则包括分析、记忆、规划和行动4个模块。

关于AI Agent的框架后文还会详细讲解。 
