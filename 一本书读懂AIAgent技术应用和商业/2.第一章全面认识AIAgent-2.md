
学习模型取得了第一名，深度学习从此开始真正在人工智能领域大显身手。


• 2016年，AlphaGO（谷歌专门从事围棋游戏的AI Agent）击败世界围棋冠军李世石。

• 2017年，谷歌发表名为“Attention is all you need”的论文，提出Transformer模型，在众多自然语言处理问题中取得了非常好的效果。而Transformer架构，正是后来OpenAI发布的GPT中的T。

• 2018年，谷歌发布基于Transformer模型的BERT，拉开了LLM的序幕。

• 2019年，谷歌AlphaStar在视频游戏《星际争霸2》上达到了Grand - master（宗师级），表现优于99.8%的人类玩家。

• 2019年，OpenAI发布GPT - 2的自然语言处理模型，并分别在2020年和2022年发布了GPT - 3、DALL·E 2及GPT - 3.5，ChatGPT的火爆为AI Agent在LLM时代的发展与应用提供了新的契机。

• 从2023年1月开始，全球厂商发布了多个LLM，其中包括LLaMA、BLOOM、StableLM、ChatGLM等开源LLM。

与此同时，全球科技厂商所推出的数以千计的LLM，为AI Agent在各领域的多元化应用提供了更广泛的基础。


2023年3月14日，OpenAI发布GPT - 4。3月底，AutoGPT横空出世，迅速火遍全球。AutoGPT是GitHub上由OpenAI推出的一个免费开源项目，结合了GPT - 4和GPT - 3.5技术，通过API创建完整的项目。与ChatGPT不同的是，在AutoGPT中用户不需要不断地向AI提问以获得对应的回答，只需为其提供一个AI名称、描述和五个目标，AutoGPT就可以自己完成项目。它可以读写文件、浏览网页、审查自己提示的结果，以及将其与所有的提示历史记录相结合。

AutoGPT也是OpenAI的一个实验性项目，用以展示GPT - 4语言模型的强大功能。它具备更多的功能，拥有更高级的智能和更大的应用潜力。在第3章，我们会详细介绍AutoGPT。

很多人在了解与体验AutoGPT的同时，也逐渐认识了AI Agent。由此开始，基于LLM的AI Agent如雨后春笋般涌现，出现了Generative Agent、GPT - Engineer、BabyAGI、MetaGPT等多个项目，这些项目的爆发将LLM的发展与应用带入了新阶段，也将LLM的创业与落地引向了AI Agent。

2023年5月，OpenAI获得新一轮3亿美元融资后，创始人Sam Altman透露更加关注如何使用聊天机器人来创建自主AI Agent，并会将相关功能部署到ChatGPT助手中。6月底，OpenAI Safety团队负责人Lilian Weng发表了一篇

|一本书读懂AI Agent：技术、应用与商业|

名为“LLM Powered Autonomous Agents”的文章，详细介绍了基于LLM的AI Agent，并认为这将是使LLM转为通用问题解决方案的途径之一。


至此，人们终于对AI Agent有了全面的了解，AI Agent的神秘面纱终于被揭开。Agent产品及Agent构建平台越来越多，这些产品及平台主要基于GPT - 4构建，也有基于开源LLM构建的。

从2023年7月开始，国内科技企业陆续推出Agent产品。

• 7月，阿里云魔搭社区推出了魔搭GPT。

• 8月，字节跳动推出了Agent构建平台豆包AI，实在智能推出了TARS - RPA - Agent。

• 8月，早在当年4月就以Agent出名的人工智能初创公司HyperWrite正式推出了AI Agent的应用AI Assistant。这是一个个人AI助理，通过Chrome浏览器的控制程序，可以帮用户订机票、订网红餐厅，甚至自动订外卖。

• 9月，来自清华大学、北京邮电大学和腾讯的研究人员提出了一个多Agent框架AgentVerse，该框架可以让多个模型进行协作，并动态调整群体的组成，实现1 + 1>2的效果。

• 10月，智谱AI推出ChatGLM3，该模型集成了智谱AI自研的AgentTuning技术，激活了模型智能体能力。

• 11月，OpenAI举办其首个开发者大会，发布其LLM最新版本GPT - 4 Turbo，推出GPT定制化服务、用于创建和管理GPT的GPT Builder与便于企业构建Agent的Assistants API，并发布了GPT Store（GPT商店）。

GPT Store的推出，让很多简单模仿、套壳OpenAI的项目估值一夜归零。而超低的“准Agent”创建门槛以及和苹果App Store一样的商业模式，必会让OpenAI快速构建GPT生态。大家可能好奇GPT为何会被称作“准Agent”或者Agent的早期版本，本书会在第三部分探讨这个问题。

OpenAI推出GPT，展示了其LLM的技术实力，也预示着个性化AI助手将成为我们日常生活中不可或缺的一部分。OpenAI开发者大会以后，比尔·盖茨在其博客上发表了一篇名为“AI is about to completely change how you use computers”的文章，该文章很快刷屏国内外媒体，并将AI Agent的探索、开发与应用推向一个新的高潮。

• 2023年12月，腾讯、百度、华为、联想、360、昆仑万维等国内公司发布了Agent相关产品及项目。同时，也有一些AI Agent相关创业项目相

12

继宣布获得融资。

• 2024年1月，OpenAI宣布正式推出GPT Store和ChatGPT Team服务。两个月之后，全网GPT数量已经超过300万个。

• 2024年2月，微软推出了名为UFO°的Windows Agent。这是一款用于构建用户界面（UI）交互智能体的Agent框架，能够快速理解和执行用户的自然语言请求。

• 2024年3月，DeepMind宣布推出可扩展可指导多世界智能体（Scalable Instructable Multiworld Agent，SIMA），这是首个能在广泛3D虚拟环境和电子游戏中遵循自然语言指令的通用AI Agent，可根据自然语言指令在各种电子游戏环境中执行任务，成为玩家搭档，帮忙干活打杂。

• 2024年4月，谷歌推出Vertex AI Agent Builder，这是一个帮助公司构建和部署AI Agent的新工具，使用户能够轻松创建和管理生成式AI驱动的AI Agent。

AI领域对于AI Agent的探索从未停止过，在每个AI技术获得全新突破之后都会有组织将其探索与应用纳入新课题。以AlphaGo为代表的深度学习与神经网络技术崭露头角后，就出现了基于深度学习及神经网络的Agent，被应用于游戏、医疗等诸多领域。而近几年LLM获得突破，在谷歌发布BERT及OpenAI发布GPT - 2后，很多组织都开始与其合作开始打造基于LLM的AI Agent。

相对而言，基于更先进的LLM以及超前的技术，AI Agent在海外的发展更快一些。我们还在谈论AI Agent的时候，海外已经出现很多AI Agent框架与产品。比如在2023年8月底完成1500万美元融资的Voiceflow，已是最受开发者欢迎的AI Agent构建平台之一，有超过13万个团队在这里高效协同、构建自己的AI Agent。从越来越多的AI Agent构建平台来看，已经有不少组织正在或者已经构建了自己的AI Agent，且每个组织都可以构建面向不同业务场景的多个AI Agent。

从哲学衍生出Agent概念，到Agent被引入AI技术，再到现在基于LLM的AI Agent，中间有几千年的跨度。而AI Agent能够在最近70多年的时间里从概念发展为越来越智能的智能硬件、智能家居、智能汽车、智慧助手、机器人等实体产品，不仅在于AI技术承载了Agent的实现路径，更在于AI技术的飞速发展。

⊖ 见论文“UFO: A UI - Focused Agent for Windows OS Interaction”，访问链接为https://arxiv.org/abs/2402.07939。

|一本书读懂AI Agent：技术、应用与商业|

# 1.2.2 AI Agent的技术演变史

AI Agent离不开AI技术的支撑，每个时代的AI Agent形态差异都取决于相关技术的突破与应用。因此了解技术演变史，有助于我们更好地理解AI Agent。AI Agent的技术演变或者说技术趋势，在复旦大学NLP团队发表的论文“The Rise and Potential of Large Language Model Based Agents: A Survey”⊖中被分为以下五个阶段。

## 阶段一：符号Agent
在AI研究的早期阶段，主要采用的方法是符号AI，其特点是依赖于符号逻辑。该方法使用逻辑规则和符号表示来封装知识并促进推理过程。早期的AI Agent基于这种方法构建，主要关注两个问题：转导问题和表示/推理问题。这种AI Agent旨在模仿人类的思维模式，拥有明确且可解释的推理框架，也因为符号性质展示出很高的表达能力，其中一个典型例子是基于知识的专家系统。

然而，符号Agent在处理不确定性和大规模实际问题方面面临限制。此外，由于符号推理算法的复杂性，寻找能够在有限时间内产生有意义结果的高效算法是很大的挑战。这些也是AI Agent技术演变的重要部分。
## 阶段二：反应型Agent

反应型Agent与符号Agent有所不同，它并不依赖复杂的符号推理。相反，它更关注Agent与环境之间的交互，强调快速和实时响应。反应型Agent主要基于感知 - 行动循环，有效地感知环境并做出反应。这种Agent的设计优先考虑直接的输入/输出映射，而不是复杂的推理和符号操作。它通常只需要较少的计算资源，能够实现更快的响应，但也存在一定的局限性，比如可能缺乏高级决策和规划能力。
## 阶段三：基于强化学习的Agent

随着计算能力和数据可用性的提高，以及自身对模拟智能Agent与其环境之间的交互的兴趣的增长，研究人员开始利用强化学习方法来训练Agent，以应对更具挑战性的复杂任务。这个领域的主要关注点是如何使Agent通过与环境的交互来学习，使其能够在特定任务中获得最大的累积奖励。

最初，强化学习Agent主要基于基本技术，如策略搜索和价值函数优化。随

⊖ 论文链接为https://arxiv.org/pdf/2309.07864.pdf。

着深度学习的兴起以及深度神经网络和强化学习的整合，深度强化学习随之出现。这使Agent可以从高维输入中学习复杂的策略，从而取得众多重大成就，如AlphaGo和DQN（深度Q网络）。这种方法的优势在于，能够让Agent在未知的环境中自主学习，无须进行人工干预。这使得它在游戏、机器人控制等多个领域中都有广泛的应用。但强化学习也面临着训练时间长、样本效率低、稳定性问题等挑战，特别是在应用于复杂的现实环境时。

## 阶段四：具有迁移学习与元学习的Agent

用传统方法训练一个基于强化学习的Agent，需要大量的样本和较长的时间，且缺乏泛化能力。因此，研究人员引入了迁移学习，以加速Agent在新任务上的学习。迁移学习减轻了新任务训练的负担，促进了知识在不同任务之间的共享和迁移，从而提高了学习效率、性能和泛化能力。

AI Agent也引入了元学习（Meta Learning）。元学习关注的是学习如何学习，使Agent能够从少量样本中快速推断出处理新任务的最优策略。在面对新任务时，这样的Agent可以利用已获得的一般知识和策略快速调整学习方法，从而减少对大量样本的依赖。当源任务和目标任务之间存在显著差异时，迁移学习的有效性可能无法达到预期，并可能出现负迁移。此外，元学习所需的大量预训练和大量样本使建立通用学习策略变得困难。这些都是AI Agent技术演变的重要部分。
## 阶段五：基于LLM的AI Agent

由于LLM展示出令人印象深刻的能力并获得了巨大的热度，研究人员开始利用LLM来构建AI Agent。具体来说，他们将LLM作为AI Agent的大脑或控制器的主要组成部分，并通过多模态感知和工具利用等策略扩展它们的感知和行动空间。这些基于LLM的AI Agent可以通过Chain - of - Thought（CoT）、问题分解等技术展示出与符号Agnet相当的推理和规划能力。

基于LLM的AI Agent还可以通过从反馈中学习和执行新的行动，获得与反应型Agent类似的与环境交互的能力。LLM在大规模语料库上进行预训练，并展示出少量样本和零样本泛化的能力，允许在任务之间无缝转移，无须更新参数。基于LLM的AI Agent已经应用于各种实际场景，如软件开发和科学研究。自然语言理解和生成能力使它们可以无缝地交互，引发多个Agent之间的协作和竞争。研究亦表明，允许多个Agent共存可以产生社会现象。

以上五个阶段构成了AI Agent的技术演变史。不同阶段的Agent形态不同、作用不同、能力不同，因而功能不同，并被应用于不同的业务场景中。从中也能

15

发现，基于LLM的AI Agent做到了集之前各类Agent之所长，更接近于专家学者所定义的理想Agent形态。

基于LLM的AI Agent是本书的重点，我们将在第3章集中讲解。

# 1.3 AI Agent的分类方式
目前常见的AI Agent分类主要有罗素和诺维格早期提出的五种方式，以及基于LLM衍生出的新方式。根据感知能力与作用目标、Agent的自主性能、Agent数量与协作能力、业务流程复杂程度，以及功能、任务与应用场景，本节将按照五种方式对AI Agent进行划分，以便读者更好地认知与理解AI Agent。
## 1.3.1 根据感知能力与作用目标划分
随着AI技术的发展，至2000年左右，Agent已经衍生出不少种类。根据Agent感知的智能和能力水平的高低，在Agent技术演变的基础上，罗素和诺维格在Artificial Intelligence: A Modern Approach（《人工智能：现代研究方法》）一书中将AI Agent分为五类。而随着LLM的发展与应用，分层Agent正在成为Agent应用的主要分类。所以，根据感知能力与作用目标，可以将Agent分为以下六种。
### 1. 简单反射Agent
简单反射Agent（Simple Reflex Agent）是一种简单的Agent类型，它基于当前的感知而不基于感知历史的其余部分。这种Agent的问题包括智力非常有限、对状态的非感知部分一无所知、生成和存储规模巨大以及无法适应环境变化。简单反射Agent的架构如图1 - 2所示。

![image](https://github.com/user-attachments/assets/a11a4fcb-7894-4fba-9e0a-13ad70a2f825)


图1 - 2 简单反射Agent的架构

简单反射Agent是一个遵循预定义规则做出决策的人工智能系统，仅对当前情况做出反应，而不考虑过去或未来的影响。它适用于具有稳定规则和直接操作的环境，其行为纯粹是反应性的，并且对即时环境变化做出响应。简单反射Agent一般遵循条件 - 动作规则来行动，该规则指定在特定条件下采取什么动作。

简单反射Agent的优点如下：

• 易于设计和实现，需要最少的计算资源；

• 实时响应环境变化；

• 在提供输入的传感器准确并且规则设计良好的情况下高度可靠；

• 不需要大量培训或复杂的硬件。

简单反射Agent的缺点如下：

• 如果提供输入的传感器有故障或规则设计不当，则容易出错；

• 没有记忆或状态，这限制了适用范围；

• 无法处理未明确编程的部分可观察性或环境变化；

• 仅限于一组特定的动作，无法适应新的情况。

### 2. 基于模型的反射Agent

基于模型的反射Agent遵循条件 - 动作规则，可以在部分可观察的环境中工作并跟踪情况。它通常由两个重要因素组成，即模型和内部状态。它可以通过获取有关世界如何演变以及Agent的操作如何影响世界的信息来更新Agent的状态。图1 - 3展示了基于模型的反射Agent的架构。

![image](https://github.com/user-attachments/assets/69e62143-62dc-44a8-9524-40a290ac32af)


图1 - 3 基于模型的反射Agent的架构

基于模型的反射Agent，根据当前感知和代表不可观测世界的内部状态执行操作。它根据两个因素更新内部状态：一是真实世界如何独立于Agent而演化，二是Agent的行为如何影响真实世界。这种Agent也遵循条件 - 动作规则，但与简单反射Agent不同，它还利用内部状态来评估决策和行动过程中的状况。基于模型的反射Agent分四个阶段运行：

1）感知：它通过传感器感知世界的当前状态。

2）模型：它根据所看到的内容构建世界的内部模型。

3）原因：它使用世界模型来决定如何根据一组预定义的规则或启发式方法采取行动。

4）行动：它执行所选择的动作。


Amazon Bedrock可以看作基于模型的反射Agent的最佳案例。它是一项使用基础模型来模拟操作、获得洞察并做出明智决策以进行有效规划和优化的服务。依靠各种模型，Amazon Bedrock获得洞察、预测结果并做出明智的决策。它利用真实世界的数据不断完善模型，使其能够适应和优化运营。它能够针对不同的场景进行规划，通过模拟和调整模型参数来选择最佳策略。

基于模型的反射Agent的优点如下：

• 基于对世界的理解快速高效地做出决策；

• 通过构建世界的内部模型，做出更准确的决策；

• 通过更新内部模型来适应环境的变化；

• 通过使用内部状态和规则来确定条件，做出更明智的战略选择。

基于模型的反射Agent的缺点如下：

• 构建和维护模型的计算成本可能很高；

• 模型可能无法很好地捕捉现实世界环境的复杂性；

• 模型无法预测可能出现的所有情况；

• 模型需要经常更新以保持最新状态；

• 模型可能在解释和理解方面带来挑战。

### 3. 基于目标的Agent

此类型根据其目标或理想情况做出决定，以便选择实现目标所需的操作。这种Agent需要进行搜索和规划，即考虑一系列可能的行动以确定目标是否达成，这使Agent具有主动性。基于目标的Agent的架构如图1 - 4所示。

基于目标的Agent是使用环境中的信息来实现特定目标的AI Agent，使用



搜索算法来寻找在给定环境中实现目标的最有效路径。这些Agent也称作基于规则的Agent，它们遵循预定义的规则来实现目标并根据某些条件采取特定动作，可以根据其期望的结果或目标确定决策和采取行动的最佳过程。

![image](https://github.com/user-attachments/assets/6f9b398b-9913-4865-84d6-49813908d843)


图1 - 4 基于目标的Agent的架构

此类Agent更易于设计并且可以处理复杂的任务，可用于机器人、计算机视觉和自然语言处理等各种应用。只要给定一个计划，基于目标的Agent就会尝试选择实现目标的最佳策略，然后使用搜索算法和启发式方法找到实现目标的有效路径。

基于目标的Agent的工作模式可以分为以下五个步骤：

1）感知：Agent使用传感器或其他输入设备感知环境，以收集有关周围环境的信息。

2）推理：Agent分析收集到的信息并决定实现目标的最佳行动方案。

3）行动：Agent采取行动来实现目标，例如移动或操纵环境中的对象。

4）评估：采取行动后，Agent评估实现目标的进度，并在必要时调整行动。

5）目标完成：一旦Agent实现了目标，它要么停止工作，要么开始致力于新的目标。

比如Google Bard就是一个典型的基于目标的Agent，它的目标是为用户查询提供高质量的响应，它选择的行动可能有助于用户找到他们想要的信息，并实现他们获得准确和有用响应的预期目标。

基于目标的Agent的优点如下：

• 易于实施和理解；

• 有效实现特定目标；

• 根据目标完成情况轻松评估绩效；

• 可以与其他人工智能技术相结合来创建更高级的Agent；

• 非常适合定义明确的结构化环境；

• 可用于各种应用，例如机器人、游戏人工智能和自动驾驶汽车。

基于目标的Agent的缺点如下：

• 仅限于特定目标；

• 无法适应不断变化的环境；

• 对于变量太多的复杂任务无效；

• 需要丰富的领域知识来定义目标。

### 4. 基于实用程序的Agent

基于实用程序的Agent的最终用途是其构建模块，当需要从多个替代方案中采取最佳行动和决策时使用。它考虑了Agent的“幸福感”，并给出了Agent由于效用而有多幸福的想法，因此具有最大效用的行动。基于实用程序的Agent是基于该效用函数或价值最大化做出决策的AI Agent，它会选择预期效用最高的行动，该效用用于衡量结果的好坏。这种方式有助于提升处理复杂和不确定情况的灵活性与适应性。这类Agent通常用于必须在多个选项之间进行比较和选择的应用程序，旨在选择导致高效用状态的操作，比如资源分配、调度和玩游戏等。基于实用程序的Agent的架构如图1 - 5所示。

![image](https://github.com/user-attachments/assets/16ca5529-9e53-4527-acad-8a593927fafe)


图1 - 5 基于实用程序的Agent的架构 
