### 第2章 AI Agent核心技术
数，使得相似的数据点在哈希后的空间中仍然保持较高的相似度，而不相似的数据点则在哈希后的空间中的相似度较低。 

LSH的工作原理基于将原始数据映射到一个较小的空间中，这个映射过程通过一个或多个哈希函数完成。这些哈希函数具有特定的性质，即它们能够保证距离相近的数据点在映射后的空间中被分配到同一个桶（hash bucket）中的概率较高，而距离较远的数据点被分配到不同桶中的概率较高。LSH的应用非常广泛，包括但不限于信息检索、数据挖掘、推荐系统和生物信息学领域。 
- **ANNOY（Approximate Nearest Neighbors Oh Yeah，近似相似就好）**：一种用于高维空间中近似最近邻搜索的高效算法，主要目的是在保证一定精度的前提下，通过牺牲一定的准确率来显著提高搜索速度。该算法的核心思想是构建一个二叉树结构，通过随机选择两个点，并使用垂直于这两个点连线的超平面将数据集分割成两部分，从而形成树的分支。这种分割方式类似于k均值的过程，但每次只聚类两个点，因而可以有效地控制树的深度和复杂度。 

在查询阶段，ANNOY算法会从根节点开始，递归地遍历树结构，直到达到预设的深度或节点数量。对于每个节点，算法都会计算查询点与当前节点的距离，并根据这个距离决定是否继续深入探索该节点的子节点。ANNOY算法的应用非常广泛，特别适用于需要快速处理大规模数据集的场景，如搜索引擎、推荐系统等。 
- **HNSW（Hierarchical Navigable Small World，分层导航更小世界）**：一种高效的近似最近邻搜索算法，广泛应用于需要快速最近邻搜索的场景，如推荐系统、图像检索和自然语言处理等。该算法通过构建层次化的图结构来实现快速、可扩展和灵活的搜索功能。 

在HNSW算法中，空间中的向量被组织成一个层次化的图结构。每个节点在插入时首先保存在第0层，然后随机选择一个层数，从该层开始逐层往下遍历，每层都将该节点插入相应的层中。这种结构使HNSW算法能够在高维数据集中有效地进行相似性搜索。HNSW算法的一个关键特点是它保持每个数据点在每层最多有M个连接的属性，这有助于平衡准确性和速度。此外，HNSW算法还具有高度的灵活性和扩展性，能够适应不同的应用场景和数据规模。 
- **FAISS（Facebook AI Similarity Search，Facebook AI相似度搜索）**：一个由Facebook开发的开源库，是一种高效的相似度搜索和索引技术。核心在于其优化的索引结构和搜索算法，专门用于高效地进行大规模向量的相似性搜索和聚类，支持稠密向量，并能够处理十亿级别的向量集。FAISS旨在加速大规模向量数据的相似度搜索，通过利用高效的索引和搜索算法，显著提高搜索效率。其主要功能包括多种索引类型，如IVF（Implicit Vector Quantization）等，这些索引类型可以根据数据特点和搜索需求进行选择。它还提供了多种算法以优化搜索过程。 
- **ScaNN（Scalable Nearest Neighbor，可扩展最近邻）**：由Google开发的近似最近邻搜索库，旨在快速、高效地处理大规模数据集的相似性搜索问题，特别是在高维空间中。它使用LSH来加速搜索过程，同时保持较高的搜索精度。ScaNN可广泛应用于机器学习、计算机视觉、自然语言处理等领域，特别适用于需要快速检索大量数据的场景，如图像检索、推荐系统等。 

### 3.工具使用 
工具使用是人类的一个非常显著且独有的特征。我们能够创造、修改并利用外部对象，完成一些超越身体和认知极限的事情。为LLM配备外部工具，可以显著提升模型的能力。图2-14展示了AI Agent的工具使用流程。 

![image](https://github.com/user-attachments/assets/f578c904-1a76-48bc-8f61-6b48866c2063)


#### （1）Agent工具使用模块 

Agent工具使用模块涉及MRKL（模块化推理、知识和语言）及TALM（工具增强语言模型）等技术的应用。 

MRKL是一个为自主Agent设计的神经符号体系结构。该系统被设想为一组“专家”模块的集合，通用的LLM则充当路由器的角色，负责将查询路由到最适合的专家模块。这些模块可以是神经的（例如深度学习模型）或符号的（例如数学计算器、货币转换器、天气API）。 

研究人员做了一个使用计算器的微调实验，以算术作为测试用例。实验结果表明，与明确表达的数学问题相比，用自然语言表达的数学问题更难解决，因为LLM（7B Jurassic1-large模型）在可靠地提取基本算术运算的参数方面存在困难。这一结果突显了当外部符号工具能够可靠工作时，知道何时以及如何使用这些工具至关重要，这取决于LLM的能力。 

TALM和语言模型自学使用工具（Toolformer）都通过微调语言模型来学习使用外部工具API。如果一个新添加的API调用注释可以提高模型输出的质量，那么数据集就会相应扩充。更多细节可以参阅翁丽莲博文“Prompt Engineering”的“外部API” 部分。 

ChatGPT插件和OpenAI API函数调用是增强LLM工具使用能力的实际示例。工具API的收集可以由其他开发人员提供（如插件），也可以是自行定义的（如函数调用）。 


#### （2）基于LLM的AI Agent如何使用工具 
就像人一样，AI Agent需要与外部工具集成或协同来完成任务，相关组件就如同AI Agent的手一样发挥作用。在准备和运行工具时通常需要进行以下几个步骤： 

1. **工具选择和适配**：根据任务需求选择合适的工具进行集成。 

2. **工具集成和接口开发**：包括数据传输、调用接口、处理返回结果等方面的工作，以确保AI Agent能够正确地与外部工具进行通信和交流。 

3. **调用工具实现任务**：通过与外部工具的交互来处理特定任务，具体的调用方法和流程会根据所选工具和任务的不同而有所差异，AI Agent可以根据需要发送指令给工具，执行特定的操作以实现任务目标。 


4. **结果处理和反馈**：在工具执行完特定任务后，AI Agent可以根据外部工具返回的结果进行处理和后续操作，这可能包括解析结果、提取关键信息、调整Agent的行为等。 

以HuggingGPT为例，这是一个AI Agent框架，它使用ChatGPT作为任务规划器，根据HuggingFace平台上可用模型的描述选择模型，并根据执行结果总结响应。如图2-15所示，该系统的运行包含4个阶段： 

- **阶段一：任务规划**。LLM充当思维大脑，将用户请求解析为多个任务。每个任务都关联有四个属性：任务类型、ID、依赖关系和参数。它们使用了几个示例来指导LLM进行任务解析和规划。 

- **阶段二：模型选择**。LLM将任务分配给专家模型，其中请求以多项选择题的形式提出。LLM需要从一个模型列表中进行选择。由于上下文长度有限，需要按任务类型进行过滤。 
- **阶段三：任务执行**。专家模型针对特定任务执行并记录结果。 
- **阶段四：响应生成**。LLM接收执行结果，并向用户提供汇总后的结果。 

![image](https://github.com/user-attachments/assets/1eaad869-9bc6-4dcc-ac9d-d7bf195fb40b)


#### （3）API-Bank的应用 
说起来很简单，但要把HuggingGPT放在真实世界中使用，需要解决很多挑战，如下： 

首先，效率是需要提升的，在LLM推理环节和与其他专有模型交互时都需要注意速度；其次，在处理复杂的任务内容时，需要一个很长的上下文；最后，LLM和外部模型服务的稳定性也需要加强。 

要衡量Agent使用工具效果的好坏，可以应用API-Bank。API-Bank是用于增强的LLM工具增强型LLM性能的基准，包含53个常用的API工具、1个完整的工具集多样化工作流以及264个标注对话，用到568次API调用。API的选择非常重要，包括搜索引擎、计算器、日历查询、智能家居控制、日程管理、健康数据管理、账户认证工作流等。由于API数量众多，LLM首先可以访问API搜索引擎，找到合适的API调用，然后使用相应的文档进行调用。 


#### （4）延伸：加强API使用 

Toolformer 用了一种新方法来学习（自学）使用工具。它以自监督的方式微调语言模型，在不失模型通用性的前提下，让模型学会自动调用API。通过调用一系列工具，包括计算器、问答系统、搜索引擎、翻译系统和日历等，Toolformer在各种下游任务中实现了实质性改进的零样本性能，通常可与更大的模型竞争，而不牺牲其核心语言建模能力。 

Toolformer的主要思路是训练一个语言模型，能够在需要的时候自动调用相关API获取答案，以提升准确性。为了将外部工具API的调用融入语言模型中，其调用、输入与输出都会以字符串的形式插入输入中。设API名称为a，输入为i，对应结果为r，在训练时，数据中在API调用位置会插入<API>a(i)→r</API>。推断时，当模型生成出→时，根据a(i)调用API得到结果r，从而借助外部工具的帮助继续生成。在这个表达式中，“<API>” “/API”和“→”都是特殊的token 。 

图2-16所示为Toolformer工作流程。给定纯文本的数据集，将该数据集转换为通过API调用增强的数据集。这包含三个步骤：采样API调用、执行API调用和过滤API调用。 

![image](https://github.com/user-attachments/assets/676b44b2-d3a3-4b4c-9f10-8efca202e6ed)


当然，Toolformer也存在不足。从训练上，使用不同工具的数据是分别生成的，这使得模型无法配合使用多种工具。使用同种工具的数据也是相互独立生成的，这使得模型无法交互地不断优化查询。从推断上，为了防止模型不断调用API导致卡死，每个样本仅允许调用一次API，这大大降低了模型的能力。 

Gorilla 由加州大学伯克利分校和微软的研究人员开发，是一个经过微调的基于LLaMA-7B的API调用模型（与API连接的LLM），该模型旨在通过解释自然语言查询来理解并准确调用1600多个API。通过使用自我指导和检索技术，选择与利用具有重叠和不断发展功能的工具。Gorilla使用全面的APIBench数据集进行评估，在生成API调用方面性能超越了GPT-4。 

为了对LLaMA进行微调，研究人员将其转换为“用户-agent”的聊天对话，其中每个数据点都是一个对话，用户和Agent各有一个回合，然后在基本的LLaMA-7B模型上进行标准的指令微调。自指示微调（self-instruct fine-tuning）和检索（retrieval）让LLM可根据API和API文档从大量重叠且多变的工具中做出准确的选择。 

Gorilla经过了在Torch Hub、TensorFlow Hub和HuggingFace等大型机器学习中心数据集上的训练。目前正在快速添加新领域，包括Kubernetes、GCP、AWS、OpenAPI等。Gorilla的性能优于GPT-4、ChatGPT和Claude，并且具有显著减少幻觉的可靠性。Gorilla还采用了Apache 2.0许可证，并在MPT和Falcon上进行微调，用户可以在商业用途中使用Gorilla而无须承担任何义务。 

对于希望自动化操作或使用API构建应用程序的开发人员来说，Gorilla是一个有用的工具。对在自然语言处理中使用API感兴趣的研究人员也可以利用它。 

ToolLLM 是基于LLaMA-7B的微调模型，属于增强LLM中的工具增强，旨在拓展LLM尤其是开源LLM的工具使用能力，为真实世界任务提供全面支持。它从RapidAPI Hub收集了16 464个真实世界的RESTful API，涵盖49个类别，然后提示ChatGPT生成涉及这些API的各种人工指令，涵盖单工具和多工具场景。 

该架构的主要创新点在于设计并开源了工具使用的调优数据集ToolBench，该数据集涵盖超过16 000个在真实世界的API和多样化的使用场景，设计并开源了包含数据构建、训练、评估全流程的框架ToolLLM。ToolLLM在工具使用任务上表现优异，性能与最先进的闭源模型ChatGPT相当。 

![image](https://github.com/user-attachments/assets/235cc4f4-3a9f-4713-aba2-d5bf1e472317)


### 图2-17 ToolLLM构建过程工作流程 

ToolLLM的特点体现于API收集、指令生成和答案标注。在API收集方面，研究人员主要从RapidAPI收集API。RapidAPI是一个托管开发者提供的大规模真实世界API的平台。研究人员将收集的所有API分为49个粗粒度类别，例如体育、金融和天气等。经过评测与筛选，留下16 464个API。在LLM的提示中有这些API相关的文档和用例。在指令生成方面，ToolLLM能够生成涉及单工具和多工具场景的指令。 

在答案标注方面，为了使搜索过程更加高效，研究人员开发了一种新颖的基于深度优先搜索的决策树（DFSDT），该算法支持语言模型去评估多条不同的推理路径，从而选择更具潜力的路径，或者移除那些不可能成功的节点。该算法使LLM能够评估多条推理路径并扩展搜索空间，能够显著增强LLM的规划和推理能力。它显著提高了标注效率，并对那些不能用CoT或ReAct回答的复杂指令进行了标注。回答不仅包括最终答案，还包括模型的推理过程、工具执行过程和工具执行结果。DFSDT与传统的CoT或ReAct的比较如图2-18所示。 

总体而言，工具使用是语言模型中的一项高级功能，关系着AI Agent执行能力的强弱。目前在工具使用方面，仅OpenAI发布的模型有较为出色的表现。相比之下，开源的LLM主要侧重于基础语言模型的优化，而在工具使用方面的表现欠佳，这也使得基于其他LLM的AI Agent在执行能力方面有所欠缺。 

ToolLLM这样的模型及数据集，对于未来开源LLM及AI Agent在工具使用方面的进一步优化具有重要的价值。随着开源LLM基础能力的不断提升，借助这些模型、工具及数据集，AI Agent将能够向更高级别的任务发起挑战并取得突破。 

![image](https://github.com/user-attachments/assets/7c308045-b314-4231-b875-19a11bef8b5b)


### 图2-18 DFSDT与传统的CoT或ReAct的比较 

### 2.4 AI Agent能力评估 
AI Agent具备很多优势，但并不是所有AI Agent都能高效完成任务以及使用工具。其中既会涉及AI Agent本身的技术性问题，也有LLM的问题。换句话说，因为使用环境、技术架构等的差异，并不是所有LLM都能保障AI Agent的正确执行。所以AI Agent的运行非常有必要引入评估体系，这是确保AI Agent有效、准确并高效地完成任务的重要手段。 

与LLM的评估类似，基于LLM的AI Agent的评估也不容易。虽然它在独立运行、集体合作和人机交互等领域表现优秀，但对其进行量化评估和客观评价仍是一大挑战。著名的图灵测试 是一种非常有意义且前景广阔的AI Agent评估方法，可用于评估人工智能系统是否能表现出类似人类的智能。但将这种测试方法用于当前的AI Agent，会过于模糊、笼统和主观。 

对于基于LLM的AI Agent的评估，复旦大学NLP团队和中国人民大学高瓴人工智能学院都在论文中给出了各自的方法。 



### 2.4.1 复旦大学NLP团队的AI Agent评估方法 

此评估方法主要关注实用性、社会性、价值观以及后续能力四个方面。 

#### （1）实用性 

目前，基于LLM的AI Agent主要被当作人类的助手，接受并完成人类的委托任务。因此，任务执行过程中的有效性和实用性是现阶段的重要评估标准。具体来说，任务完成的成功率是评估实用性的主要指标。这一指标主要包括AI Agent是否实现了规定的目标或达到了预期的分数。例如，AgentBench 汇总了来自不同真实世界场景的挑战，并引入了一个系统基准来评估LLM的任务完成能力。 

我们还可以将任务结果归因于AI Agent的各种基础能力，如环境理解能力、推理能力、规划能力、决策能力、工具使用能力和行动能力，并对这些具体能力进行更详细的评估。此外，由于基于LLM的AI Agent规模相对较大，我们还应考虑其效率因素，这是决定用户满意度的关键因素。AI Agent不仅要有足够的实力，还要能在适当的时间范围内以适当的资源消耗完成预定的任务。 

#### （2）社会性 

除了在完成任务和满足人类需求方面的实用性外，基于LLM的AI Agent的社会性也至关重要。社会性影响用户的交流体验，并对交流效率产生重大影响，涉及它们是否能与人类和其他AI Agent进行无缝互动。具体来说，可以从以下几个角度来评估社会性： 
- **语言交流能力**：是一种基本能力，包括自然语言理解和生成。它是NLP界长期关注的焦点。自然语言理解要求AI Agent不仅能理解字面意思，还能掌握隐含的意思和相关的社会知识，如幽默、讽刺、攻击和情感等。自然语言生成要求AI Agent生成流畅、语法正确、可信的内容，同时根据上下文环境调整适当的语气和情感。 
- **合作与协商能力**：要求AI Agent在有序和无序的情况下有效执行指定任务。它们应与其他AI Agent合作或竞争，以提高性能。测试环境可能涉及需要AI Agent合作完成的复杂任务，也可能涉及供AI Agent自由交互的开放平台。评价指标不仅包括任务完成情况，还包括AI Agent协调与合作的顺畅度和信任度。 
- **角色扮演能力**：要求AI Agent忠实地体现其被分配的角色，表达与其指定身份一致的言论并执行相应的行动。这就确保了在与其他AI Agent或人类互动时角色的明确区分。此外，在执行长期任务时，AI Agent应保持其身份，避免不必要的混淆。 
#### （3）价值观 
随着基于LLM的AI Agent能力的不断提升，确保AI Agent对世界和人类无害至关重要。因此，适当的评估变得异常重要，这也是保证AI Agent实际应用的基础。具体来说，基于LLM的AI Agent需要遵守符合人类社会

价值观的特定道德和伦理准则。我们对AI Agent的首要期望是坚持诚信，提供准确、真实的信息和内容。它们应具备辨别自己是否有能力完成任务的意识，并在无法提供答案或帮助时表达自己的不确定性。 

AI Agent必须保持无害立场，避免直接或间接的偏见、歧视、攻击或类似行为，还应避免执行人类要求的危险行动，如制造破坏性工具或破坏地球。同时，AI Agent应能够适应特定的人口、文化和环境，在特定情况下表现出与环境相适应的社会价值观。价值观的相关评估方法主要包括在构建的诚实、无害或特定情境基准上评估性能，利用对抗性攻击或“越狱”攻击，通过人类注释对价值观进行评分，以及利用其他AI Agent进行评级。 
#### （4）后续能力 

从静态的角度来看，具有高实用性、社交性和适当价值观的AI Agent可以满足大多数人类需求，并可能提高生产力。但从动态的角度来看，一个能够不断进化并适应不断变化的社会需求的AI Agent更加符合当前趋势。由于AI Agent可以随着时间的推移自主进化，所需的人力干预和资源可能会显著减少（例如数据收集工作和训练的计算成本）。 

在这一领域已经有人开展了一些探索性工作，例如让AI Agent在虚拟世界中从零开始，完成生存任务，实现更高阶的自我价值。为AI Agent的持续进化建立评估标准有很大的挑战性，复旦大学NLP团队在已有文献基础上提出了一些初步意见和建议，包括以下几个方面： 
- **持续学习能力**：持续学习能力是一个在机器学习领域讨论已久的话题，旨在使模型在获得新知识和技能的同时，不会遗忘之前获得的知识和技能（也称为灾难性遗忘）。一般来说，持续学习的性能可从三个方面进行评估：迄今所学任务的总体性能、旧任务的记忆稳定性、新任务的学习可塑性。 
- **自主学习能力**：AI Agent在开放世界环境中自主生成目标并实现目标的能力 。 
