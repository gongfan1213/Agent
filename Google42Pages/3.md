### Production applications with Vertex AI agents
While this whitepaper explored the core components of agents, building production - grade applications requires integrating them with additional tools like user interfaces, evaluation frameworks, and continuous improvement mechanisms. Google’s Vertex AI platform simplifies this process by offering a fully managed environment with all the fundamental elements covered earlier. Using a natural language interface, developers can rapidly define crucial elements of their agents - goals, task instructions, tools, sub - agents for task delegation, and examples - to easily construct the desired system behavior. In addition, the platform comes with a set of development tools that allow for testing, evaluation, measuring agent performance, debugging, and improving the overall quality of developed agents. This allows developers to focus on building and refining their agents while the complexities of infrastructure, deployment and maintenance are managed by the platform itself.


虽然本白皮书探讨了代理的核心组件，但构建生产级应用程序需要将它们与用户界面、评估框架和持续改进机制等其他工具集成。Google Vertex AI 平台通过提供包含前文所述所有基本元素的完全托管环境，简化了这一流程。使用自然语言界面，开发者可以快速定义代理的关键元素——目标、任务指令、工具、用于任务委派的子代理以及示例——从而轻松构建所需的系统行为。此外，该平台还附带一套开发工具，可用于测试、评估、衡量代理性能、调试以及提升已开发代理的整体质量。这使得开发者可以专注于构建和完善代理，而基础架构、部署和维护的复杂性则由平台本身管理。

![image](https://github.com/user-attachments/assets/2ce09522-334b-4bb1-aca9-a40f66ce30cc)



In Figure 15 we’ve provided a sample architecture of an agent that was built on the Vertex AI platform using various features such as Vertex Agent Builder, Vertex Extensions, Vertex Function Calling and Vertex Example Store to name a few. The architecture includes many of the various components necessary for a production - ready application.

You can try a sample of this prebuilt agent architecture from our official documentation.

图 15 中，我们提供了一个基于 Vertex AI 平台构建的代理示例架构，该架构使用了 Vertex Agent Builder、Vertex Extensions、Vertex Function Calling 和 Vertex Example Store 等多种功能。该架构包含生产就绪应用程序所需的各种组件。

您可以从我们的官方文档中试用此预构建代理架构的示例。



### Summary
In this whitepaper we’ve discussed the foundational building blocks of Generative AI agents, their compositions, and effective ways to implement them in the form of cognitive architectures. Some key takeaways from this whitepaper include:

1. Agents extend the capabilities of language models by leveraging tools to access real - time information, suggest real - world actions, and plan and execute complex tasks autonomously. Agents can leverage one or more language models to decide when and how to transition through states and use external tools to complete any number of complex tasks that would be difficult or impossible for the model to complete on its own.

2. At the heart of an agent’s operation is the orchestration layer, a cognitive architecture that structures reasoning, planning, decision - making and guides its actions. Various reasoning techniques such as ReAct, Chain - of - Thought, and Tree - of - Thoughts, provide a framework for the orchestration layer to take in information, perform internal reasoning, and generate informed decisions or responses.

3. Tools, such as Extensions, Functions, and Data Stores, serve as the keys to the outside world for agents, allowing them to interact with external systems and access knowledge beyond their training data. Extensions provide a bridge between agents and external APIs, enabling the execution of API calls and retrieval of real - time information. Functions provide a more nuanced control for the developer through the division of labor, allowing agents to generate Function parameters which can be executed client - side. Data Stores provide agents with access to structured or unstructured data, enabling data - driven applications.

The future of agents holds exciting advancements and we’ve only begun to scratch the surface of what is possible. As tools become more sophisticated and reasoning capabilities are enhanced, agents will be empowered to solve increasingly complex problems. Furthermore, the strategic approach of ‘agent chaining’ will continue to gain momentum. By combining specialized agents - each excelling in a particular domain or task - we can create a ‘mixture of agent experts’ approach, capable of delivering exceptional results across various industries and problem areas.

It’s important to remember that building complex agent architectures demands an iterative approach. Experimentation and refinement are key to finding solutions for specific business cases and organizational needs. No two agents are created alike due to the generative nature of the foundational models that underpin their architecture. However, by harnessing the strengths of each of these foundational components, we can create impactful applications that extend the capabilities of language models and drive real - world value.

在本白皮书中，我们讨论了生成式人工智能代理的基本构建模块、其组成以及以认知架构形式实现这些代理的有效方法。本白皮书的一些关键要点包括：
1. 代理通过利用工具访问实时信息、建议现实世界中的操作以及自主规划和执行复杂任务，从而扩展了语言模型的功能。代理可以利用一个或多个语言模型来决定何时以及如何转换状态，并使用外部工具来完成模型自身难以或无法完成的任意数量的复杂任务。

2. 代理运行的核心是编排层，这是一种认知架构，它构建推理、规划、决策并指导其行动。各种推理技术（例如 ReAct、思想链和思想树）为编排层提供了一个框架，用于接收信息、执行内部推理并生成明智的决策或响应。

3. 诸如扩展程序、函数和数据存储之类的工具是智能体与外界沟通的钥匙，使它们能够与外部系统交互并获取训练数据以外的知识。扩展程序在智能体和外部 API 之间架起了一座桥梁，支持执行 API 调用和检索实时信息。函数通过分工为开发人员提供更精细的控制，允许智能体生成可在客户端执行的函数参数。数据存储使智能体能够访问结构化或非结构化数据，从而实现数据驱动的应用程序。

智能体的未来充满着激动人心的进步，而我们才刚刚开始触及其可能性的表面。随着工具日益复杂，推理能力不断增强，智能体将能够解决日益复杂的问题。此外，“智能体链”这一战略方法将继续获得发展。通过组合专门的智能体（每个智能体在特定领域或任务上都表现出色），我们可以创建一种“智能体专家组合”的方法，能够在各个行业和问题领域提供卓越的成果。

务必记住，构建复杂的代理架构需要一种迭代方法。实验和改进是找到满足特定业务案例和组织需求的解决方案的关键。由于支撑其架构的基础模型具有生成性，因此没有两个代理是完全相同的。然而，通过利用每个基础组件的优势，我们可以创建有效的应用程序，扩展语言模型的功能并推动现实世界的价值。

### Endnotes
1. Shafran, I., Cao, Y. et al., 2022, 'ReAct: Synergizing Reasoning and Acting in Language Models'. Available at: https://arxiv.org/abs/2210.03629
2. Wei, J., Wang, X. et al., 2023, 'Chain - of - Thought Prompting Elicits Reasoning in Large Language Models'. Available at: https://arxiv.org/pdf/2201.11903.pdf.
3. Wang, X. et al., 2022, 'Self - Consistency Improves Chain of Thought Reasoning in Language Models'. Available at: https://arxiv.org/abs/2203.11171.
4. Diao, S. et al., 2023, 'Active Prompting with Chain - of - Thought for Large Language Models'. Available at: https://arxiv.org/pdf/2302.12246.pdf.
5. Zhang, H. et al., 2023, 'Multimodal Chain - of - Thought Reasoning in Language Models'. Available at: https://arxiv.org/abs/2302.00923.
6. Yao, S. et al., 2023, 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models'. Available at: https://arxiv.org/abs/2305.10601.
7. Long, X., 2023, 'Large Language Model Guided Tree - of - Thought'. Available at: https://arxiv.org/abs/2305.08291.
8. Google. 'Google Gemini Application'. Available at: http://gemini.google.com.
9. Swagger. 'OpenAPI Specification'. Available at: https://swagger.io/specification/.
10. Xie, M., 2022, 'How does in - context learning work? A framework for understanding the differences from traditional supervised learning'. Available at: https://ai.stanford.edu/blog/understanding - in - context/.
11. Google Research. 'ScaNN (Scalable Nearest Neighbors)'. Available at: https://github.com/google - research/google - research/tree/master/scann.
12. LangChain. 'LangChain'. Available at: https://python.langchain.com/v0.2/docs/introduction/.

September 2024
