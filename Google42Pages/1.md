# Agents

### Authors: Julia Wiesinger, Patrick Marlow 
and Vladimir Vuskovic

## 致谢

审阅者和贡献者

Evan Huang

Emily Xue

Olcan Sercinoglu

Sebastian Riedel

Satinder Baveja

Antonio Gulli

Anant Nawalgaria



策展者和编辑

Antonio Gulli

Anant Nawalgaria

Grace Mollison



技术写作

Joey Haymaker

设计师

Michael Lanning


# Agents
**Authors**: Julia Wiesinger, Patrick Marlow and Vladimir Vuskovic

Google

**Acknowledgements**
**Reviewers and Contributors**
Evan Huang Emily Xue Olcan Sercinoglu Sebastian Riedel Satinder Baveja Antonio Gulli Anant Nawalgaria
**Curators and Editors**
Antonio Gulli Anant Nawalgaria Grace Mollison
**Technical Writer**
Joey Haymaker
**Designer**
Michael Lanning

September 2024

## Table of contents
- Introduction 4
- What is an agent? 5
    - The model 6
    - The tools 7
    - The orchestration layer 7
- Agents vs. models 8
- Cognitive architectures: How agents operate 8
- Tools: Our keys to the outside world 12
    - Extensions 13
    - Sample Extensions 15
    - Functions 18
- Use cases 21
    - Function sample code 24
    - Data stores 27
- Implementation and application 28
    - Tools recap 32
    - Enhancing model performance with targeted learning 33
    - Agent quick start with LangChain 35
    - Production applications with Vertex AI agents 38
- Summary 40
- Endnotes 42

## Agents
This combination of reasoning, logic, and access to external information that are all connected to a Generative AI model invokes the concept of an agent.


结合推理、逻辑以及对外部信息的访问，这些能力与生成式 AI 模型相连，诞生了代理的概念。

## Introduction
Humans are fantastic at messy pattern recognition tasks. However, they often rely on tools - like books, Google Search, or a calculator - to supplement their prior knowledge before arriving at a conclusion. Just like humans, Generative AI models can be trained to use tools to access real-time information or suggest a real-world action. For example, a model can leverage a database retrieval tool to access specific information, like a customer's purchase history, so it can generate tailored shopping recommendations. Alternatively, based on a user's query, a model can make various API calls to send an email response to a colleague or complete a financial transaction on your behalf. To do so, the model must not only have access to a set of external tools, it needs the ability to plan and execute any task in a self-directed fashion. This combination of reasoning, logic, and access to external information that are all connected to a Generative AI model invokes the concept of an agent, or a program that extends beyond the standalone capabilities of a Generative AI model. This whitepaper dives into all these and associated aspects in more detail.

人类非常擅长处理复杂的模式识别任务。然而，他们常常需要依赖书籍、谷歌搜索或计算器等工具来补充已有的知识，然后得出结论。同样，生成式 AI 模型也可以通过使用工具来访问实时信息或建议现实中的操作。例如，模型可以利用数据库检索工具来访问特定信息，比如客户的购买历史，从而生成个性化的购物推荐。此外，根据用户的查询，模型可以进行各种 API 调用，比如发送邮件回复给同事或代表用户完成一笔金融交易。为了实现这些功能，模型不仅需要具备访问一组外部工具的能力，还需要能够自主规划和执行任务。这种结合了推理、逻辑和外部信息访问的能力，与生成式 AI 模型相结合，就引出了代理（agent）的概念。代理是一种超越单一生成式 AI 模型能力的程序。本白皮书将详细探讨这些及相关的内容。





September 2024

## What is an agent?
In its most fundamental form, a Generative AI agent can be defined as an application that attempts to achieve a goal by observing the world and acting upon it using the tools that it has at its disposal. Agents are autonomous and can act independently of human intervention, especially when provided with proper goals or objectives they are meant to achieve. Agents can also be proactive in their approach to reaching their goals. Even in the absence of explicit instruction sets from a human, an agent can reason about what it should do next to achieve its ultimate goal. While the notion of agents in AI is quite general and powerful, this whitepaper focuses on the specific types of agents that Generative AI models are capable of building at the time of publication.

从最基础的角度来说，生成式 AI 代理可以定义为一种通过观察世界并使用其可用工具采取行动以实现目标的应用程序。代理是自主的，可以在没有人类干预的情况下独立运行，尤其是在明确提供了目标或任务的情况下。此外，代理在实现目标的过程中还可以表现出主动性。即使在没有明确的指令下，代理也可以推断出下一步应该做什么，以达成最终目标。尽管 AI 中的代理概念非常广泛且强大，本白皮书重点探讨的是生成式 AI 模型当前能够构建的特定类型的代理。

In order to understand the inner workings of an agent, let’s first introduce the foundational components that drive the agent’s behavior, actions, and decision making. The combination of these components can be described as a cognitive architecture, and there are many such architectures that can be achieved by the mixing and matching of these components. Focusing on the core functionalities, there are three essential components in an agent’s cognitive architecture as shown in Figure 1.

为了理解代理的内部工作原理，我们首先需要介绍驱动代理行为、行动和决策的核心组件。这些组件的组合可以描述为一种认知架构，通过不同组件的搭配可以实现多种架构。关注核心功能，代理的认知架构有以下三个关键组件，如图 1 所示。

September 2024


![image](https://github.com/user-attachments/assets/608725bc-3153-4ab9-8d35-f9e59aaa63d1)

### The model
In the scope of an agent, a model refers to the language model (LM) that will be utilized as the centralized decision maker for agent processes. The model used by an agent can be one or multiple LM’s of any size (small / large) that are capable of following instruction based reasoning and logic frameworks, like ReAct, Chain-of-Thought, or Tree-of-Thoughts. Models can be general purpose, multimodal or fine-tuned based on the needs of your specific agent architecture. For best production results, you should leverage a model that best fits your desired end application and, ideally, has been trained on data signatures associated with the tools that you plan to use in the cognitive architecture. It’s important to note that the model is typically not trained with the specific configuration settings (i.e. tool choices, orchestration/ reasoning setup) of the agent. However, it’s possible to further refine the model for the agent’s tasks by providing it with examples that showcase the agent’s capabilities, including instances of the agent using specific tools or reasoning steps in various contexts.

在代理的范围内，模型是指将作为代理流程中心决策者的语言模型（LM）。代理所使用的模型可以是一个或多个任何规模的语言模型（小型/大型），这些模型能够遵循基于指令的推理和逻辑框架，如 ReAct、Chain-of-Thought 或 Tree-of-Thoughts。根据代理架构的具体需求，模型可以是通用的、多模态的，或经过微调的。为了获得最佳的生产效果，应选择最符合目标应用的模型，并优先选择在与计划使用的工具相关数据特征上经过训练的模型。需要注意的是，模型通常不会针对代理的具体配置设置（如工具选择、编排/推理设置）进行训练。然而，可以通过为模型提供示例来进一步优化其任务能力，这些示例展示了代理在不同情境中使用特定工具或推理步骤的能力。


September 2024

### The tools
Foundational models, despite their impressive text and image generation, remain constrained by their inability to interact with the outside world. Tools bridge this gap, empowering agents to interact with external data and services while unlocking a wider range of actions beyond that of the underlying model alone. Tools can take a variety of forms and have varying depths of complexity, but typically align with common web API methods like GET, POST, PATCH, and DELETE. For example, a tool could update customer information in a database or fetch weather data to influence a travel recommendation that the agent is providing to the user. With tools, agents can access and process real-world information. This empowers them to support more specialized systems like retrieval augmented generation (RAG), which significantly extends an agent’s capabilities beyond what the foundational model can achieve on its own. We’ll discuss tools in more detail below, but the most important thing to understand is that tools bridge the gap between the agent’s internal capabilities and the external world, unlocking a broader range of possibilities.

尽管基础模型在文本和图像生成方面表现令人印象深刻，但它们无法与外部世界交互的局限性仍然存在。工具弥补了这一缺陷，使代理能够与外部数据和服务交互，并解锁基础模型无法单独完成的更多操作。工具形式多样，复杂程度不一，但通常与常见的 Web API 方法（如 GET、POST、PATCH 和 DELETE）一致。例如，一个工具可以更新数据库中的客户信息，或获取天气数据以优化旅行推荐。有了工具，代理能够访问并处理现实世界中的信息。这使代理能够支持更复杂的系统，如检索增强生成（RAG），显著扩展了代理的能力，使其远超基础模型本身。我们将在后文更详细地讨论工具，但最重要的是，工具连接了代理的内部能力与外部世界，解锁了更多可能性。




### The orchestration layer
The orchestration layer describes a cyclical process that governs how the agent takes in information, performs some internal reasoning, and uses that reasoning to inform its next action or decision. In general, this loop will continue until an agent has reached its goal or a stopping point. The complexity of the orchestration layer can vary greatly depending on the agent and task it’s performing. Some loops can be simple calculations with decision rules, while others may contain chained logic, involve additional machine learning algorithms, or implement other probabilistic reasoning techniques. We’ll discuss more about the detailed implementation of the agent orchestration layers in the cognitive architecture section.

编排层描述了一个循环过程，控制代理如何获取信息、执行内部推理，并利用这些推理来决定下一步行动或决策。一般而言，这种循环会持续进行，直到代理达成目标或到达终点。根据代理及其任务的不同，编排层的复杂性可能有很大差异。一些循环可能只是简单的计算和决策规则，而另一些则可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。在后续认知架构部分，我们将深入讨论代理编排层的详细实现。


September 2024

## Agents vs. models
To gain a clearer understanding of the distinction between agents and models, consider the following chart:
| Models | Agents |
| --- | --- |
| Knowledge is limited to what is available in their training data. | Knowledge is extended through the connection with external systems via tools |
| Single inference / prediction based on the user query. Unless explicitly implemented for the model, there is no management of session history or continuous context. (i.e. chat history) | Managed session history (i.e. chat history) to allow for multi turn inference / prediction based on user queries and decisions made in the orchestration layer. In this context, a ‘turn’ is defined as an interaction between the interacting system and the agent. (i.e. 1 incoming event/ query and 1 agent response) |
| No native tool implementation. | Tools are natively implemented in agent architecture. |
| No native logic layer implemented. Users can form prompts as simple questions or use reasoning frameworks (CoT, ReAct, etc.) to form complex prompts to guide the model in prediction. | Native cognitive architecture that uses reasoning frameworks like CoT, ReAct, or other pre-built agent frameworks like LangChain. |

|对比项|模型|代理|
|--|--|--|
|知识获取范围|局限于训练数据中可用信息|通过工具连接外部系统，扩展知识获取范围|
|推理及上下文管理|基于用户查询进行单次推理/预测，通常不管理会话历史或连续上下文（除非专门实现）|管理会话历史（如聊天记录），支持基于用户查询和编排层决策的多轮推理/预测，“轮次”指交互系统与代理间一次交互（1次输入事件/查询和1次代理响应）|
|工具实现|无内置工具实现|工具原生集成在代理架构中|
|逻辑架构|无内置逻辑层，用户需用简单问题提示或复杂推理框架（如CoT、ReAct等）构建提示来指导模型预测|内置认知架构，使用CoT、ReAct等推理框架或预构建代理框架（如LangChain）  | 

![image](https://github.com/user-attachments/assets/15d52ce4-d2d1-4606-bb4a-f4cb3033df41)


## Cognitive architectures: How agents operate
Imagine a chef in a busy kitchen. Their goal is to create delicious dishes for restaurant patrons which involves some cycle of planning, execution, and adjustment.

想象一下，厨房里有一位忙碌的厨师。他的目标是为餐厅顾客制作美味的菜肴，而这需要经历一系列的规划、执行和调整循环

September 2024
- They gather information, like the patron’s order and what ingredients are in the pantry and refrigerator.
- They perform some internal reasoning about what dishes and flavor profiles they can create based on the information they have just gathered.
- They take action to create the dish: chopping vegetables, blending spices, searing meat.

他们收集信息，例如顾客的订单，以及储藏室和冰箱中的食材。

他们进行内部推理，基于刚刚收集的信息思考可以制作哪些菜品和风味组合。

他们采取行动制作菜肴：切菜、混合调料、煎烤肉类。

At each stage in the process the chef makes adjustments as needed, refining their plan as ingredients are depleted or customer feedback is received, and uses the set of previous outcomes to determine the next plan of action. This cycle of information intake, planning, executing, and adjusting describes a unique cognitive architecture that the chef employs to reach their goal.

在整个过程中，厨师会根据需要进行调整，例如食材不足或接收到顾客的反馈，从而优化计划，并利用之前的经验决定下一步行动。这种信息摄取、规划、执行和调整的循环，描述了厨师为了达成目标所使用的一种独特认知架构。

Just like the chef, agents can use cognitive architectures to reach their end goals by iteratively processing information, making informed decisions, and refining next actions based on previous outputs. At the core of agent cognitive architectures lies the orchestration layer, responsible for maintaining memory, state, reasoning and planning. It uses the rapidly evolving field of prompt engineering and associated frameworks to guide reasoning and planning, enabling the agent to interact more effectively with its environment and complete tasks. Research in the area of prompt engineering frameworks and task planning for language models is rapidly evolving, yielding a variety of promising approaches. While not an exhaustive list, these are a few of the most popular frameworks and reasoning techniques available at the time of this publication:

与厨师类似，代理也可以使用认知架构，通过反复处理信息、做出明智的决策，并根据之前的输出优化下一步行动来实现最终目标。在代理的认知架构核心中，编排层负责维护记忆、状态、推理和规划。它利用快速发展的提示工程领域及相关框架来指导推理和规划，从而使代理更高效地与环境交互并完成任务。在提示工程框架和语言模型任务规划领域的研究正在迅速发展，产生了许多有前景的方法。以下是目前几种较为流行的框架和推理技术（非完整列表）：


- ReAct, a prompt engineering framework that provides a thought process strategy for language models to Reason and take action on a user query, with or without in-context examples. ReAct prompting has shown to outperform several SOTA baselines and improve human interoperability and trustworthiness of LLMs.
- Chain-of-Thought (CoT), a prompt engineering framework that enables reasoning capabilities through intermediate steps. There are various sub-techniques of CoT including self-consistency, active-prompt, and multimodal CoT that each have strengths and weaknesses depending on the specific application.
- Tree-of-thoughts (ToT), a prompt engineering framework that is well suited for exploration or strategic lookahead tasks. It generalizes over chain-of-thought prompting and allows the model to explore various thought chains that serve as intermediate steps for general problem solving with language models.

ReAct：一种提示工程框架，向语言模型提供思考和行动策略，用于处理用户查询，可包含上下文示例，也可不包含。ReAct 提示已被证明优于多个当前最优基线，并提高了大型语言模型的可互操作性和可信度。

Chain-of-Thought (CoT)：一种通过中间步骤实现推理能力的提示工程框架。CoT 包括多种子技术，如自一致性、主动提示和多模态 CoT，这些技术在不同应用场景中各有优劣。

Tree-of-Thoughts (ToT)：一种适用于探索或战略性前瞻任务的提示工程框架。它是对 Chain-of-Thought 提示的推广，允许模型探索作为问题解决中间步骤的多条思维链。


Agents can utilize one of the above reasoning techniques, or many other techniques, to choose the next best action for the given user request. For example, let’s consider an agent that is programmed to use the ReAct framework to choose the correct actions and tools for the user query. The sequence of events might go something like this:

代理可以利用上述推理技术之一或其他技术，根据用户请求选择最佳行动。例如，假设一个代理被编程为使用 ReAct 框架来选择正确的操作和工具处理用户查询，事件序列可能如下：

1. User sends query to the agent

2. Agent begins the ReAct sequence

3. The agent provides a prompt to the model, asking it to generate one of the next ReAct steps and its corresponding output:
    - Question: The input question from the user query, provided with the prompt
    - Thought: The model’s thoughts about what it should do next
    - Action: The model’s decision on what action to take next
        - This is where tool choice can occur
        - For example, an action could be one of [Flights, Search, Code, None], where the first 3 represent a known tool that the model can choose, and the last represents “no tool choice”
    - Action input: The model’s decision on what inputs to provide to the tool (if any)
    - Observation: The result of the action / action input sequence
        - This thought / action / action input / observation could repeat N - times as needed
    - Final answer: The model’s final answer to provide to the original user query
4. The ReAct loop concludes and a final answer is provided back to the user


1.用户向代理发送查询。
2.代理启动 ReAct 流程。
3.代理向模型提供一个提示，要求其生成下一个 ReAct 步骤及其相应输出：
    - 问题 (Question)：用户查询中的输入问题，包含在提示中。
    - 思考 (Thought)：模型关于下一步行动的思考。
    - 行动 (Action)：模型决定下一步要采取的行动：

这是工具选择的地方，例如，行动可能是以下之一：[Flights（航班）、Search（搜索）、Code（代码）、None（无工具选择）]。
    - 行动输入 (Action input)：模型决定提供给工具的输入（如果有）。
    - 观察 (Observation)：行动/行动输入序列的结果。
            这一“思考/行动/行动输入/观察”过程可以根据需要重复多次。
    - 最终答案 (Final answer)：模型提供给用户查询的最终答案。
4.ReAct 循环结束，代理向用户提供最终答案

![image](https://github.com/user-attachments/assets/5f339bb8-1fec-4080-9d30-63cceb3d2c3a)

图 2. 在编排层中使用 ReAct 推理的代理示例


As shown in Figure 2, the model, tools, and agent configuration work together to provide a grounded, concise response back to the user based on the user’s original query. While the model could have guessed at an answer (hallucinated) based on its prior knowledge, it instead used a tool (Flights) to search for real-time external information. This additional information was provided to the model, allowing it to make a more informed decision based on real factual data and to summarize this information back to the user.

如图 2 所示，模型、工具和代理配置协同工作，为用户的原始查询提供基于事实的简明响应。虽然模型可以基于其先前的知识猜测答案（产生幻觉），但它选择使用工具（如 Flights）搜索实时的外部信息。这些附加信息被提供给模型，使其能够基于真实的事实数据做出更明智的决策，并将这些信息总结后返回给用户。

In summary, the quality of agent responses can be tied directly to the model’s ability to reason and act about these various tasks, including the ability to select the right tools, and how well that tools has been defined. Like a chef crafting a dish with fresh ingredients and attentive to customer feedback, agents rely on sound reasoning and reliable information to deliver optimal results. In the next section, we’ll dive into the various ways agents connect with fresh data.

代理的响应质量直接取决于模型对任务的推理和行动能力，包括选择合适工具的能力以及工具定义的质量。就像厨师使用新鲜食材制作菜肴并关注顾客反馈一样，代理依赖于稳健的推理和可靠的信息来提供最佳结果。在下一节中，我们将深入探讨代理如何与新鲜数据连接。

## Tools: Our keys to the outside world
While language models excel at processing information, they lack the ability to directly perceive and influence the real world. This limits their usefulness in situations requiring interaction with external systems or data. This means that, in a sense, a language model is only as good as what it has learned from its training data. But regardless of how much data we throw at a model, they still lack the fundamental ability to interact with the outside world. So how can we empower our models to have real-time, context-aware interaction with external systems? Functions, Extensions, Data Stores and Plugins are all ways to provide this critical capability to the model.

尽管语言模型在信息处理方面表现出色，但它们缺乏直接感知和影响现实世界的能力。这限制了它们在需要与外部系统或数据交互的场景中的实用性。换句话说，语言模型的能力取决于其训练数据。然而，无论向模型输入多少数据，它们依然缺乏与外部世界交互的基本能力。那么，我们如何让模型能够与外部系统实时、上下文相关地交互呢？函数（Functions）、扩展（Extensions）、数据存储（Data Stores） 和 插件（Plugins） 是实现这一关键能力的几种方式。


While they go by many names, tools are what create a link between our foundational models and the outside world. This link to external systems and data allows our agent to perform a wider variety of tasks and do so with more accuracy and reliability. For instance, tools can enable agents to adjust smart home settings, update calendars, fetch user information from a database, or send emails based on a specific set of instructions.

As of the date of this publication, there are three primary tool types that Google models are able to interact with: Extensions, Functions, and Data Stores. By equipping agents with tools, we unlock a vast potential for them to not only understand the world but also act upon it, opening doors to a myriad of new applications and possibilities.

尽管名称各异，但“工具”就是连接基础模型与外部世界的桥梁。这一连接外部系统和数据的能力使代理能够执行更多种类的任务，并以更高的准确性和可靠性完成任务。例如，工具可以使代理调整智能家居设置、更新日历、从数据库获取用户信息，或根据特定指令发送电子邮件。截至本白皮书发布日期，Google 模型能够交互的三种主要工具类型是：扩展、函数和数据存储。通过为代理配备工具，我们为其打开了理解和作用于世界的大门，为各种新应用和可能性提供了广阔的空间。



September 2024

### Extensions
The easiest way to understand Extensions is to think of them as bridging the gap between an API and an agent in a standardized way, allowing agents to seamlessly execute APIs regardless of their underlying implementation. Let’s say that you’ve built an agent with a goal of helping users book flights. You know that you want to use the Google Flights API to retrieve flight information, but you’re not sure how you’re going to get your agent to make calls to this API endpoint.


要理解扩展，可以将其视为在 API 和代理之间建立标准化桥梁的一种方式，使代理能够无缝执行 API，而不受其底层实现的限制。假设您构建了一个代理，目标是帮助用户预订航班。您知道需要使用 Google Flights API 来获取航班信息，但您不确定如何让代理调用该 API 端点。

![image](https://github.com/user-attachments/assets/4ef5d3fc-8b97-43aa-b2cf-dbebdafdc8f4)

图 3. 代理如何与外部 API 交互？

One approach could be to implement custom code that would take the incoming user query, parse the query for relevant information, then make the API call. For example, in a flight booking use case a user might state “I want to book a flight from Austin to Zurich.” In this scenario, our custom code solution would need to extract “Austin” and “Zurich” as relevant entities from the user query before attempting to make the API call. But what happens if the user says “I want to book a flight to Zurich” and never provides a departure city? The API call would fail without the required data and more code would need to be implemented in order to catch edge and corner cases like this. This approach is not scalable and could easily break in any scenario that falls outside of the implemented custom code.

一种方法是实现自定义代码，解析用户查询中的相关信息，然后调用 API。例如，在航班预订用例中，用户可能会说：“我想预订从奥斯汀飞往苏黎世的航班。”此场景下，您的自定义代码需要从用户查询中提取“奥斯汀”和“苏黎世”作为相关实体，然后尝试调用 API。但如果用户说“我想预订飞往苏黎世的航班”，却未提供出发城市会怎样？API 调用会因缺少必要数据而失败，此时需要额外编写代码来处理这些边缘和极端情况。这种方法不具备可扩展性，并且在任何未涵盖的场景下都容易出错。

A more resilient approach would be to use an Extension. An Extension bridges the gap between an agent and an API by:
1. Teaching the agent how to use the API endpoint using examples.
2. Teaching the agent what arguments or parameters are needed to successfully call the API endpoint.

更具弹性的方法是使用扩展。扩展通过以下方式在代理和 API 之间建立桥梁：

1.教授代理如何使用 API 端点（通过示例）。

2.教授代理调用 API 端点时需要哪些参数或参数。

![image](https://github.com/user-attachments/assets/2add8385-7ee0-43bd-adc5-fc954ac876bc)


Extensions can be crafted independently of the agent, but should be provided as part of the agent’s configuration. The agent uses the model and examples at run time to decide which Extension, if any, would be suitable for solving the user’s query. This highlights a key strength of Extensions, their built-in example types, that allow the agent to dynamically select the most appropriate Extension for the task.

扩展可以独立于代理开发，但应作为代理配置的一部分提供。代理在运行时使用模型和示例来决定哪种扩展（如果有）最适合解决用户的查询。这突出显示了扩展的一个关键优势：内置的示例类型，允许代理动态选择最合适的扩展完成任务

![image](https://github.com/user-attachments/assets/85af75e8-c5ea-4934-b1c1-90aa52b938a9)


Think of this the same way that a software developer decides which API endpoints to use while solving and solutioning for a user’s problem. If the user wants to book a flight, the developer might use the Google Flights API. If the user wants to know where the nearest coffee shop is relative to their location, the developer might use the Google Maps API. In this same way, the agent / model stack uses a set of known Extensions to decide which one will be the best fit for the user’s query. If you’d like to see Extensions in action, you can try them out on the Gemini application by going to Settings > Extensions and then enabling any you would like to test. For example, you could enable the Google Flights extension then ask Gemini “Show me flights from Austin to Zurich leaving next Friday.”

可以将其类比为软件开发人员在为用户问题设计解决方案时决定使用哪些 API 端点的过程。例如，如果用户想预订航班，开发人员可能会使用 Google Flights API；如果用户想知道离他们最近的咖啡店位置，开发人员可能会使用 Google Maps API。同样，代理/模型堆栈使用一组已知的扩展来决定哪个最适合用户的查询。如果您想看到扩展的实际应用，可以在 Gemini 应用中进入 设置 > 扩展，启用您希望测试的扩展。例如，您可以启用 Google Flights 扩展，然后询问 Gemini：“显示下周五从奥斯汀飞往苏黎世的航班。”



### Sample Extensions
To simplify the usage of Extensions, Google provides some out-of-the-box extensions that can be quickly imported into your project and used with minimal configurations. For example, the Code Interpreter extension in Snippet 1 allows you to generate and run Python code from a natural language description.

为了简化扩展的使用，Google 提供了一些开箱即用的扩展，可以快速导入到您的项目中，并以最少的配置进行使用。例如，代码解释器扩展（Code Interpreter Extension）可以根据自然语言描述生成并运行 Python 代码，如代码片段 1 所示。

```python
import vertexai
import pprint
PROJECT_ID = "YOUR_PROJECT_ID" 
REGION = "us-central1"
vertexai.init(project=PROJECT_ID, location=REGION)
from vertexai.preview.extensions import Extension
extension_code_interpreter = Extension.from_hub("code_interpreter") 
CODE_QUERY = """Write a python method to invert a binary tree in O(n) time."""
response = extension_code_interpreter.execute(
    operation_id = "generate_and_execute",
    operation_params = {"query": CODE_QUERY}
)
print("Generated Code:")
pprint.pprint({response['generated_code']})
```
```python
# The above snippet will generate the following code.
Generated Code:
class TreeNode:
    def __init__(self, val=0, left=None, right=None):
        self.val = val
        self.left = left 
        self.right = right
def invert_binary_tree(root):
    """
    Returns: Args: Inverts a binary tree. The root of the inverted binary tree. root: The root of the binary tree.
    """
    if not root:
        return None
    # Swap the left and right children recursively
    root.left, root.right = invert_binary_tree(root.right), invert_binary_tree(root.left)
    return root
# Example usage:
# Construct a sample binary tree 
root = TreeNode(4) 
root.left = TreeNode(2) 
root.right = TreeNode(7) 
root.left.left = TreeNode(1)
root.left.right = TreeNode(3)
root.right.left = TreeNode(6)
root.right.right = TreeNode(9)
# Invert the binary tree 
inverted_root = invert_binary_tree(root)
```

代码片段 1：代码解释器扩展（Code Interpreter Extension）可以生成并运行 Python 代码。


To summarize, Extensions provide a way for agents to perceive, interact, and influence the outside world in a myriad of ways. The selection and invocation of these Extensions is guided by the use of Examples, all of which are defined as part of the Extension configuration.

总结来说，扩展提供了一种方式，使代理能够以多种方式感知、交互并影响外部世界。扩展的选择和调用通过示例引导，所有示例均作为扩展配置的一部分定义。



### Functions
In the world of software engineering, functions are defined as self-contained modules of code that accomplish a specific task and can be reused as needed. When a software developer is writing a program, they will often create many functions to do various tasks. They will also define the logic for when to call function_a versus function_b, as well as the expected inputs

在软件工程中，函数是定义为完成特定任务的独立代码模块，可以根据需要重复使用。当软件开发人员编写程序时，他们通常会创建多个函数来完成不同的任务，并定义调用函数 A 或函数 B 的逻辑，以及期望的输入和输出。

在代理的世界中，函数的工作方式非常相似，但我们可以将软件开发人员替换为模型。模型可以根据函数的规范决定何时使用已知的函数，以及函数需要哪些参数。函数与扩展之间存在以下显著区别：

# P18到这

