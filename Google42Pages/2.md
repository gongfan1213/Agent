and outputs.

Functions work very similarly in the world of agents, but we can replace the software developer with a model. A model can take a set of known functions and decide when to use each Function and what arguments the Function needs based on its specification. Functions differ from Extensions in a few ways, most notably:

在软件工程中，也就是我们日常写代码时，“函数”指的是自包含的代码模块，用于完成特定任务，并可以复用（被不同地方的代码调用）。 软件工程师写程序时，通常会创建许多函数来执行各种任务，还会定义函数的预期输入和输出。

在 Agent 的世界中，函数的工作方式非常相似 —— 只是将“软件开发者”替换为“模型”。 模型可以设置一组已知的函数，然后就可以根据规范决定何时使用哪个函数，以及函数需要哪些参数。


1. A model outputs a Function and its arguments, but doesn’t make a live API call.

2. Functions are executed on the client - side, while Extensions are executed on the agent - side.

1.模型只输出函数名及其参数信息，但不会执行函数；

2.函数在客户端执行。作为对比，Extension 在 Agent 端执行。见下图，






Using our Google Flights example again, a simple setup for functions might look like the example in Figure 7.

再次使用我们的Google Flights示例，一个简单的函数设置可能类似于图7中的示例。


![image](https://github.com/user-attachments/assets/3f71bbb6-9506-4845-92c0-6fc45333d091)


图7: 函数如何与外部 API 交互？



Note that the main difference here is that neither the Function nor the agent interact directly with the Google Flights API. So how does the API call actually happen?

请注意，这里的主要区别是函数和智能体都不直接与Google Flights API交互。那么，API调用实际上是如何发生的呢？


With functions, the logic and execution of calling the actual API endpoint is offloaded away from the agent and back to the client - side application as seen in Figure 8 and Figure 9 below. This offers the developer more granular control over the flow of data in the application. There are many reasons why a Developer might choose to use functions over Extensions, but a few common use cases are:

对于函数来说，调用API接口的逻辑和实际执行都从智能体那里转移到了客户端应用，就像下面图8和图9展示的那样。这样做可以让开发人员更细致地控制应用里的数据流。开发人员有很多理由会选择用函数而不是扩展，下面是一些常见的用例：


- API calls need to be made at another layer of the application stack, outside of the direct agent architecture flow (e.g. a middleware system, a front end framework, etc.)
- Security or Authentication restrictions that prevent the agent from calling an API directly (e.g API is not exposed to the internet, or non - accessible by agent infrastructure)
- Timing or order - of - operations constraints that prevent the agent from making API calls in real - time. (i.e. batch operations, human - in - the - loop review, etc.)
- Additional data transformation logic needs to be applied to the API Response that the agent cannot perform. For example, consider an API endpoint that doesn’t provide a filtering mechanism for limiting the number of results returned. Using Functions on the client - side provides the developer additional opportunities to make these transformations.
- The developer wants to iterate on agent development without deploying additional infrastructure for the API endpoints (i.e. Function Calling can act like “stubbing” of APIs)

- 需要在应用程序堆栈的另一层（在直接智能体架构流程之外）进行API调用（例如，中间件系统、前端框架等）。
- 存在安全或身份验证限制，阻止智能体直接调用API（例如，API未暴露于互联网，或智能体基础设施无法访问）。
- 存在时序或操作顺序约束，阻止智能体实时进行API调用（例如，批量操作、人工审核等）。
- 需要对API响应应用额外的据转换逻辑，而智能体无法执行此操作。例如，有些API接口不提供过滤机制来限制返回结果数量的。在客户端使用函数就能让开发人员有更多机会来进行这些处理。
- 开发人员可能想在不为API接口部署额外基础设施的情况下进行智能体开发迭代（也就是说，函数调用可以起到“桩代码”的作用）。

While the difference in internal architecture between the two approaches is subtle as seen in Figure 8, the additional control and decoupled dependency on external infrastructure makes Function Calling an appealing option for the Developer.

虽然如图8所示，这两种方法在内部架构上差别不大，但因为函数调用提供了额外的控制，并且不用那么依赖外部的基础设施，所以对开发人员来说，它还是挺有吸引力的。

图8: 说明扩展和函数调用中，哪些是客户端控制的，哪些是智能体控制的

![image](https://github.com/user-attachments/assets/33ef2b71-81a0-45dc-868a-7ecbb261eafc)


### Use cases
A model can be used to invoke functions in order to handle complex, client - side execution flows for the end user, where the agent Developer might not want the language model to manage the API execution (as is the case with Extensions). Let’s consider the following example where an agent is being trained as a travel concierge to interact with users that want to book vacation trips. The goal is to get the agent to produce a list of cities that we can use in our middleware application to download images, data, etc. for the user’s trip planning. A user might say something like:

可以使用模型来调用函数，以便为最终用户处理复杂的客户端执行流程，在这种情况下，智能体开发人员可能不希望语言模型管理API执行（就像使用扩展的情况一样）。让我们考虑以下示例，其中一个智能体正在接受培训，作为旅行管家与想要预订度假旅行的用户互动。目标是让智能体生成一个城市列表，我们可以在中间件应用程序中使用该列表来为用户的旅行计划下载图像、数据等。用户可能会说这样的话：


I’d like to take a ski trip with my family but I’m not sure where to go.

In a typical prompt to the model, the output might look like the following:

Sure, here’s a list of cities that you can consider for family ski trips:
- Crested Butte, Colorado, USA
- Whistler, BC, Canada
- Zermatt, Switzerland

  我想和家人一起去滑雪旅行，但我不知道去哪里。

在一般情况下，给模型的提示可能会得到这样的输出：

没问题，这里有一些你可以考虑的适合家庭滑雪旅行的城市：

Crested Butte, Colorado, USA
Whistler, BC, Canada
Zermatt, Switzerland



While the above output contains the data that we need (city names), the format isn’t ideal for parsing. With Function Calling, we can teach a model to format this output in a structured style (like JSON) that’s more convenient for another system to parse. Given the same input prompt from the user, an example JSON output from a Function might look like Snippet 5 instead.

虽然上面的输出包含了我们需要的数据（城市名），但格式不太好解析。有了函数调用，我们可以教模型把输出弄成结构化的格式（例如JSON），这样其他系统解析起来就方便多了。用户还是给出同样的提问，用函数得到的JSON输出可能就像代码片段5那样。

代码片段5 展示城市列表和用户爱好的函数调用数据示例



```json
function_call { 
    name: "display_cities",
    args: { 
        "cities": ["Crested Butte", "Whistler", "Zermatt"], 
        "preferences": "skiing" 
    } 
}
```
This JSON payload is generated by the model, and then sent to our Client - side server to do whatever we would like to do with it. In this specific case, we’ll call the Google Places API to take the cities provided by the model and look up Images, then provide them as formatted rich content back to our User. Consider this sequence diagram in Figure 9 showing the above interaction in step - by - step detail.

这个JSON数据是模型生成的，然后会发送到我们的客户端服务器，我们想怎么用就怎么用。在这个例子里，我们会调用Google Places API，拿到模型给出的城市，然后查出图片，再把这些图片弄成格式好看的富文本内容返回给用户。具体的过程可以看下面的图9，里面一步一步地画得很清楚。

图9: 函数调用时序图

![image](https://github.com/user-attachments/assets/94f5e554-0ee9-4622-ad62-b4a035c024b1)


The result of the example in Figure 9 is that the model is leveraged to “fill in the blanks” with the parameters required for the Client side UI to make the call to the Google Places API. The Client side UI manages the actual API call using the parameters provided by the model in the returned Function. This is just one use case for Function Calling, but there are many other scenarios to consider like:

图9中的例子说明，模型的作用是“填空”，把客户端UI调用Google Places API需要的参数都填上。然后客户端UI就用模型在返回的函数里提供的参数来真正地调用API。这只是函数调用的一个用法，还有很多其他的情况也需要考虑，例如：


- You want a language model to suggest a function that you can use in your code, but you don't want to include credentials in your code. Because function calling doesn't run the function, you don't need to include credentials in your code with the function information.
- You are running asynchronous operations that can take more than a few seconds. These scenarios work well with function calling because it's an asynchronous operation.
- You want to run functions on a device that's different from the system producing the function calls and their arguments.


你希望语言模型给你推荐一些可以在代码里用的函数，但你又不想把凭据(credentials)写到代码里。因为函数调用并不会真的去执行函数，所以你就不需要在代码里连同函数信息一起写上凭据了。
如果你在运行一些需要好几秒甚至更长时间的异步操作，那就很适合用函数调用，因为它自己就是异步的。
你希望在与生成函数调用和参数的那个系统不同的设备上运行函数。


One key thing to remember about functions is that they are meant to offer the developer much more control over not only the execution of API calls, but also the entire flow of data in the application as a whole. In the example in Figure 9, the developer chose to not return API information back to the agent as it was not pertinent for future actions the agent might take. However, based on the architecture of the application, it may make sense to return the external API call data to the agent in order to influence future reasoning, logic, and action choices. Ultimately, it is up to the application developer to choose what is right for the specific application.

说到函数，得记住很重要的一点，就是它们让开发者能更好地控制API调用怎么执行，还有整个应用的数据是怎么流动的。就像图9那个例子，开发者没把API信息返回给智能体，因为觉得对它后面的行动没啥用。不过，要是从应用的架构来看，把外部API调用的数据返回给智能体，来影响它后面的推理、逻辑和行动，也是可以的。总之，怎么做还得看具体的应用，开发者自己说了算。



### Function sample code
To achieve the above output from our ski vacation scenario, let’s build out each of the components to make this work with our gemini - 1.5 - flash - 001 model.

First, we’ll define our display_cities function as a simple Python method.

为了从我们的滑雪度假场景中获得上述输出，让我们构建各个组成部分，以使其能够与我们的gemini-1.5-flash-001模型协同工作。首先，我们将display_cities函数定义为一个简单的Python函数。

代码片段6 一个用于显示城市列表功能的Python函数


```python
from typing import Optional

def display_cities(cities: list[str], preferences: Optional[str] = None):
    """Provides a list of cities based on the user's search query and preferences.
    Args:
        preferences (str): The user's preferences for the search, like skiing,
        beach, restaurants, bbq, etc.
        cities (list[str]): The list of cities being recommended to the user.
    Returns:
        list[str]: The list of cities being recommended to the user. 
    """
    return cities
```
Next, we’ll instantiate our model, build the Tool, then pass in our user’s query and tools to the model. Executing the code below would result in the output as seen at the bottom of the code snippet.

接下来，我们将实例化我们的模型，构建工具，然后将用户的查询和工具传递给模型。执行以下代码将产生代码片段底部所示的输出。

代码片段7 构建一个工具，然后将其与用户查询一同发送给模型，并允许函数调用得以执行


```python
from vertexai.generative_models import GenerativeModel, Tool, FunctionDeclaration

model = GenerativeModel("gemini - 1.5 - flash - 001")
display_cities_function = FunctionDeclaration.from_func(display_cities)
tool = Tool(function_declarations=[display_cities_function])
message = "I’d like to take a ski trip with my family but I’m not sure where to go."
res = model.generate_content(message, tools=[tool])
print(f"Function Name: {res.candidates[0].content.parts[0].function_call.name}")
print(f"Function Args: {res.candidates[0].content.parts[0].function_call.args}")
```
```
> Function Name: display_cities
> Function Args: {'preferences':'skiing', 'cities': ['Aspen', 'Vail', 'Park City']}
```
In summary, functions offer a straightforward framework that empowers application developers with fine - grained control over data flow and system execution, while effectively leveraging the agent/model for critical input generation. Developers can selectively choose whether to keep the agent “in the loop” by returning external data, or omit it based on specific application architecture requirements.


总之，函数提供了一个简单的框架，让应用程序开发者可以非常精细地控制数据怎么流动、系统怎么运行，同时还能有效地利用智能体/模型来生成重要的输入。开发者可以根据具体的应用架构来选择，是把外部数据返回给智能体让它“参与其中”，还是不返回。


### Data stores
Imagine a language model as a vast library of books, containing its training data. But unlike a library that continuously acquires new volumes, this one remains static, holding only the knowledge it was initially trained on. This presents a challenge, as real - world knowledge is constantly evolving. Data Stores address this limitation by providing access to more dynamic and up - to - date information, and ensuring a model’s responses remain grounded in factuality and relevance.

将语言模型想象成一座藏书丰富的巨型图书馆，其馆藏即为其训练数据。然而，与不断购入新书的图书馆不同，这座图书馆是静态的，仅保存其最初训练时所获得的知识。这便带来了一个挑战，因为现实世界的知识是不断发展的。数据存储就是为了解决这个问题而生的，它可以让模型访问更动态、更新的信息，保证模型说出来的话都是有根据、有用的。

考虑一种常见的情形，即开发者可能需要向模型提供少量额外数据，例如以电子表格或PDF的形式。

图10: 智能体如何与结构化和非结构化数据进行交互？

![image](https://github.com/user-attachments/assets/2cff5a2b-7a1c-46a2-83d8-9f5c15e2b056)


Consider a common scenario where a developer might need to provide a small amount of additional data to a model, perhaps in the form of spreadsheets or PDFs.

Data Stores allow developers to provide additional data in its original format to an agent, eliminating the need for time - consuming data transformations, model retraining, or fine - tuning. The Data Store converts the incoming document into a set of vector database embeddings that the agent can use to extract the information it needs to supplement its next action or response to the user.

数据存储让开发者可以直接用原始格式给智能体提供额外的数据，就不用花时间去做数据转换、重新训练模型或者微调了。数据存储会把收到的文档转换成一组向量数据库的嵌入(embeddings)，智能体可以用这些嵌入来提取它需要的信息，补充它接下来的行动或者回复用户。

图11: 数据存储让智能体能够连接到各种新的实时数据源

![image](https://github.com/user-attachments/assets/278d59c4-167d-4c52-a539-b4c8510a2ab9)

### Implementation and application

3.3.1 实现与应用 

在生成式AI智能体领域，数据存储通常以向量数据库的形式实现，开发者希望智能体在运行时能够访问该数据库。虽然本文不深入探讨向量数据库，

但需要理解的关键点是，它们以向量嵌入的形式存储数据，向量嵌入是一种高维向量或所提供数据的数学表示。近期，语言模型中使用数据存储最显著的例子之一是基于检索增强生成 (RAG) 的应用程序的实现。这些应用程序旨在通过使模型能够访问各种格式的数据:

- 网站内容

- 结构化数据，格式包括PDF、Word 文档、CSV、电子表格等。

- 非结构化数据，格式包括HTML、PDF、TXT等。

图12: 智能体和数据存储之间是一对多的关系，表示一个智能体可以对应多个预先建好索引的数据


In the context of Generative AI agents, Data Stores are typically implemented as a vector database that the developer wants the agent to have access to at runtime. While we won’t cover vector databases in depth here, the key point to understand is that they store data in the form of vector embeddings, a type of high - dimensional vector or mathematical representation of the data provided. One of the most prolific examples of Data Store usage with language models in recent times has been the implementation of Retrieval Augmented Generation (RAG) based applications. These applications seek to extend the breadth and depth of a model’s knowledge beyond the foundational training data by giving the model access to data in various formats like:
- Website content
- Structured Data in formats like PDF, Word Docs, CSV, Spreadsheets, etc.
- Unstructured Data in formats like HTML, PDF, TXT, etc.

![image](https://github.com/user-attachments/assets/4a5ae8d2-9f3d-4d58-a745-faec919b69bb)


The underlying process for each user request and agent response loop is generally modeled as seen in Figure 13.
1. A user query is sent to an embedding model to generate embeddings for the query
2. The query embeddings are then matched against the contents of the vector database using a matching algorithm like SCaNN
3. The matched content is retrieved from the vector database in text format and sent back to the agent
4. The agent receives both the user query and retrieved content, then formulates a response or action
5. A final response is sent to the user


每个用户请求和智能体响应循环的基本过程通常如图13所示。

1.用户查询被发送到嵌入模型以生成查询的嵌入。

2.然后使用诸如 SCaNN 之类的匹配算法将查询嵌入与向量数据库的内容进行匹配。

3.匹配的内容以文本格式从向量数据库中检索并发送回智能体。

4.智能体接收用户查询和检索到的内容，然后形成响应或采取行动。

最终响应被发送给用户。


图13: RAG应用中用户请求和智能体响应应的整个流程


![image](https://github.com/user-attachments/assets/4483218f-b68f-4d78-b0a7-9079c3bb45f8)


The end result is an application that allows the agent to match a user’s query to a known data store through vector search, retrieve the original content, and provide it to the orchestration layer and model for further processing. The next action might be to provide a final answer to the user, or perform an additional vector search to further refine the results.

A sample interaction with an agent that implements RAG with ReAct reasoning/planning can be seen in Figure 14.

最终结果是一个应用程序，该应用程序允许智能体通过向量搜索将用户查询与已知数据存储进行匹配，检索原始内容，并将其提供给编排层和模型以进行进一步处理。下一步操作可能是向用户提供最终答案，或者执行额外的向量搜索以进一步优化结果。

图14展示了一个使用ReAct推理/行动实现RAG的智能体的交互示例。

图14: ReAct推理/行动 RAG 应用示例

![image](https://github.com/user-attachments/assets/4a416546-4348-4224-be0c-cff505196e26)


## Implementation and application
In the context of Generative AI agents, the components we've discussed - models, tools, and the orchestration layer - come together in various ways. For example, in a customer service application, an agent might use a model to understand a customer's query. Based on the query, it could select an appropriate tool, like an Extension to access a customer database or a Function to format the response in a specific way. The orchestration layer would manage the flow, ensuring that the agent takes the right actions at each step, using techniques like ReAct or Chain - of - Thought to reason about the best course of action.

### Tools recap
To summarize, extensions, functions and data stores make up a few different tool types available for agents to use at runtime. Each has their own purpose and they can be used together or independently at the discretion of the agent developer.

3.3 工具总结 #

总的来说，扩展、函数和数据存储是智能体在运行时可用的几种不同工具类型。它们各有用途，智能体开发者可以根据需要单独或组合使用它们。

![image](https://github.com/user-attachments/assets/3a48b827-9ec2-4d44-be76-d9ba715a1619)


| | Extensions | Function Calling | Data Stores |
|--|--|--|--|
| Execution | Agent - Side Execution | Client - Side Execution | Agent - Side Execution |
| Use Case | Developer wants agent to control interactions with the API endpoints; Useful when leveraging native pre - built Extensions (i.e. Vertex Search, Code Interpreter, etc.) | API calls need to be made at another layer of the application stack; Security or Authentication restrictions prevent the agent from calling an API directly; Timing constraints or order - of - operations constraints that prevent the agent from making API calls in real - time; Additional data transformation logic needs to be applied to the API Response that the agent cannot perform; The developer wants to iterate on agent development without deploying additional infrastructure for the API endpoints | Developer wants to implement Retrieval Augmented Generation (RAG) with any of the following data types: Website Content from pre - indexed domains and URLs; Structured Data in formats like PDF, Word Docs, CSV, Spreadsheets, etc.; Unstructured Data in formats like HTML, PDF, TXT, etc.; Relational / Non - Relational Databases |

|执行方式|扩展 (Extensions)|函数调用 (Function Calling)|数据存储 (Data Stores)|
| ---- | ---- | ---- | ---- |
|执行 (Execution)|智能体端执行 (Agent-Side Execution)|客户端执行 (Client-Side Execution)|智能体端执行 (Agent-Side Execution)|
|用例 (Use Case)|开发者希望智能体控制与API端点的交互。在利用原生预构建扩展（例如Vertex搜索、代码解释器等）时非常有用。多跳规划和API调用（即，下一个智能体操作取决于先前操作/API调用的输出）。|安全或身份验证限制阻止智能体直接调用API。时序约束或操作顺序约束阻止智能体实时进行API调用。（例如，批量操作、人工审核等）。未向互联网公开或Google系统无法访问的API。|开发者希望使用以下任何数据类型实现检索增强生成 (RAG)：来自预索引域和URL的网站内容；PDF、Word文档、CSV、电子表格等格式的结构化数据；关系/非关系数据库；HTML、PDF、TXT等格式的非结构化数据| 



### Enhancing model performance with targeted learning
A crucial aspect of using models effectively is their ability to choose the right tools when generating output, especially when using tools at scale in production. While general training helps models develop this skill, real - world scenarios often require knowledge beyond the training data. Imagine this as the difference between basic cooking skills and mastering a specific cuisine. Both require foundational cooking knowledge, but the latter demands targeted learning for more nuanced results.

4.通过针对性学习提升模型性能 #

有效使用模型的关键方面之一是其在生成输出时选择正确工具的能力，尤其是在生产环境中大规模使用工具时。虽然一般训练有助于模型培养这项技能，但实际场景通常需要超出训练数据的知识。可以将此比作基本烹饪技巧与精通特定菜系之间的差异。两者都需要基础烹饪知识，但后者需要有针对性的学习才能获得更精细的结果。

为了帮助模型获得此类特定知识，存在几种方法：


To help the model gain access to this type of specific knowledge, several approaches exist:
- In - context learning: This method provides a generalized model with a prompt, tools, and few - shot examples at inference time which allows it to learn ‘on the fly' how and when to use those tools for a specific task. The ReAct framework is an example of this approach in natural language.
- Retrieval - based in - context learning: This technique dynamically populates the model prompt with the most relevant information, tools, and associated examples by retrieving them from external memory. An example of this would be the ‘Example Store’ in Vertex AI extensions or the data stores RAG based architecture mentioned previously.
- Fine - tuning based learning: This method involves training a model using a larger dataset of specific examples prior to inference. This helps the model understand when and how to apply certain tools prior to receiving any user queries.

  为了帮助模型获得此类特定知识，存在几种方法：

- In-context learning(上下文学习)：此方法在推理时为通用模型提供提示、工具和少量示例，使其能够“即时”学习如何以及何时针对特定任务使用这些工具。ReAct 框架是自然语言中此方法的一个示例。
- Retrieval-based in-context learning(基于检索的上下文学习)：此技术通过从外部记忆中检索最相关的信息、工具和相关示例，动态填充模型提示。Vertex AI 扩展中的“示例存储”或先前所述的基于 RAG 架构的数据存储是这方面的一个例子。
- Fine-tuning based learning(基于微调的学习)：此方法包括在推理之前使用更大的特定示例数据集训练模型。这有助于模型在接收任何用户查询之前了解何时以及如何应用某些工具。

To provide additional insights on each of the targeted learning approaches, let’s revisit our cooking analogy.
- Imagine a chef has received a specific recipe (the prompt), a few key ingredients (relevant tools) and some example dishes (few - shot examples) from a customer. Based on this limited information and the chef’s general knowledge of cooking, they will need to figure out how to prepare the dish ‘on the fly’ that most closely aligns with the recipe and the customer’s preferences. This is in - context learning.
- Now let’s imagine our chef in a kitchen that has a well - stocked pantry (external data stores) filled with various ingredients and cookbooks (examples and tools). The chef is now able to dynamically choose ingredients and cookbooks from the pantry and better align to the customer’s recipe and preferences. This allows the chef to create a more informed and refined dish leveraging both existing and new knowledge. This is retrieval - based in - context learning.
- Finally, let’s imagine that we sent our chef back to school to learn a new cuisine or set of cuisines (pre - training on a larger dataset of specific examples). This allows the chef to approach future unseen customer recipes with deeper understanding. This approach is perfect if we want the chef to excel in specific cuisines (knowledge domains). This is fine - tuning based learning.

为了更深入地了解每种方法，再来看看我们之前关于烹饪的例子。

想象一下，一位厨师收到了一份特定的食谱（提示）、一些关键食材（相关工具）以及一些菜肴示例（少量示例），均来自顾客。基于这些有限的信息以及厨师的一般烹饪知识，他们需要“即时”弄清楚如何烹制最符合食谱和顾客偏好的菜肴。这就是上下文学习。

现在，让我们设想这位厨师在一个储备充足的食品储藏室（外部数据存储）的厨房里，那里摆放着各种食材和食谱（示例和工具）。厨师现在能够从储藏室中动态选择食材和食谱，并更好地符合顾客的食谱和偏好。这使得厨师能够利用现有知识和新知识，创造出更丰富、更精致的菜肴。这就是基于检索的上下文学习。

最后，让我们设想我们将这位厨师送回学校学习新的菜系或一系列菜系（使用更大的特定示例数据集进行预训练）。这使得厨师能够以更深入的理解来处理未来未见过的顾客食谱。如果我们希望厨师在特定菜系（知识领域）中表现出色，这种方法是完美的。这就是基于微调的学习。

Each of these approaches offers unique advantages and disadvantages in terms of speed, cost, and latency. However, by combining these techniques in an agent framework, we can leverage the various strengths and minimize their weaknesses, allowing for a more robust and adaptable solution.

就速度、成本和延迟而言，这些方法各有优缺点。然而，通过在智能体框架中结合这些技术，我们可以利用各种优势并最大限度地减少其缺点，从而实现更强大、更具适应性的解决方案。


### Agent quick start with LangChain
In order to provide a real - world executable example of an agent in action, we’ll build a quick prototype with the LangChain and LangGraph libraries. These popular open - source libraries allow users to build customer agents by “chaining” together sequences of logic, reasoning, and tool calls to answer a user’s query. We’ll use our gemini - 1.5 - flash - 001 model and some simple tools to answer a multi - stage query from the user as seen in Snippet 8.

5.使用LangChain快速上手智能体 


为了提供一个实际可执行的智能体应用示例，我们将使用LangChain和LangGraph库构建一个快速原型。这些流行的开源库允许用户通过“链接(chaining)”一系列逻辑、推理和工具调用来构建自定义智能体，以回答用户查询。我们将使用gemini-1.5-flash-001模型和一些简单的工具来回答用户在代码片段8中所展示的多阶段查询。

The tools we are using are the SerpAPI (for Google Search) and the Google Places API. After executing our program in Snippet 8, you can see the sample output in Snippet 9.

我们使用的工具是SerpAPI（用于Google搜索）和 Google Places API。执行代码片段8中的程序后，您可以在代码片段9中看到示例输出。

代码片段8 带有工具的基于 LangChain 和 LangGraph 的智能体示例

```python
import os
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from langchain_community.utilities import SerpAPIWrapper
from langchain_community.tools import GooglePlacesTool

os.environ["SERPAPI_API_KEY"] = "XXXXX"
os.environ["GPLACES_API_KEY"] = "XXXXX"

@tool
def search(query: str): 
    """Use the SerpAPI to run a Google Search."""
    search = SerpAPIWrapper()
    return search.run(query)

@tool
def places(query: str):
    """Use the Google Places API to run a Google Places Query."""
    places = GooglePlacesTool()
    return places.run(query)

from vertexai.preview.language_models import ChatVertexAI
model = ChatVertexAI(model="gemini - 1.5 - flash - 001")
tools = [search, places]
query = "Who did the Texas Longhorns play in football last week? What is the address of the other team's stadium?"
agent = create_react_agent(model, tools) 
input = {"messages": [("human", query)]}
for s in agent.stream(input, stream_mode="values"):
    message = s["messages"][-1]
    if isinstance(message, tuple):
        print(message)
    else:
        message.pretty_print()
```
Snippet 8. Sample LangChain and LangGraph based agent with tools

代码片段9 代码片段8中程序的输出


```
=============================== Human Message ================================
Who did the Texas Longhorns play in football last week? What is the address of the other team's stadium?
================================= Ai Message =================================
Tool Calls: search
Args:
query: Texas Longhorns football schedule
================================ Tool Message ================================
Name: search
{...Results: "NCAA Division I Football, Georgia, Date..."}
================================= Ai Message =================================
The Texas Longhorns played the Georgia Bulldogs last week. Tool Calls: places
Args:
query: Georgia Bulldogs stadium
================================ Tool Message ================================
Name: places
..........:
{...Sanford Stadium Address: 100 Sanford...}
================================= Ai Message =================================
The address of the Georgia Bulldogs stadium is 100 Sanford Dr, Athens, GA 30602, USA.
```
While this is a fairly simple agent example, it demonstrates the foundational components of Model, Orchestration, and tools all working together to achieve a specific goal. In the final section, we’ll explore how these components come together in Google - scale managed products like Vertex AI


虽然这是一个相当简单的智能体示例，但它展示了模型、编排和工具等基本组件如何协同工作以实现特定目标。在最后一节中，我们将探讨这些组件如何在 Google 规模的托管产品（例如 Vertex AI 智能体和 Generative Playbooks）中结合使用。
